{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mloscratch/homes/ordonnea/conda/envs/graph_rag/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mloscratch/homes/ordonnea/conda/envs/graph_rag/lib/python3.12/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_url\" in LlamaCPP has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/mloscratch/homes/ordonnea/conda/envs/graph_rag/lib/python3.12/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_path\" in LlamaCPP has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/mloscratch/homes/ordonnea/conda/envs/graph_rag/lib/python3.12/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_kwargs\" in LlamaCPP has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import nest_asyncio\n",
    "from datasets import load_dataset\n",
    "\n",
    "import re\n",
    "\n",
    "import json\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification, AutoModelForCausalLM\n",
    "import networkx as nx\n",
    "import spacy\n",
    "from itertools import combinations\n",
    "\n",
    "from llama_index.core import (\n",
    "    KnowledgeGraphIndex,\n",
    "    StorageContext,\n",
    "    Document,\n",
    "    Settings,\n",
    "    SimpleDirectoryReader\n",
    ")\n",
    "from llama_index.core import KnowledgeGraphIndex, StorageContext\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.schema import TextNode, NodeRelationship\n",
    "from llama_index.core.indices.property_graph import SchemaLLMPathExtractor\n",
    "from llama_index.core.query_engine import KnowledgeGraphQueryEngine\n",
    "from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n",
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "from llama_index.llms.llama_cpp import LlamaCPP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading url https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q4_0.gguf to path /tmp/llama_index/models/Meta-Llama-3-8B-Instruct.Q4_0.gguf\n",
      "total size (MB): 4661.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4446it [00:20, 213.70it/s]                          \n",
      "llama_model_loader: loaded meta data with 27 key-value pairs and 291 tensors from /tmp/llama_index/models/Meta-Llama-3-8B-Instruct.Q4_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Models\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 8.0B\n",
      "llama_model_loader: - kv   4:                            general.license str              = llama3\n",
      "llama_model_loader: - kv   5:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv   6:                          general.languages arr[str,1]       = [\"en\"]\n",
      "llama_model_loader: - kv   7:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   8:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  15:                          general.file_type u32              = 2\n",
      "llama_model_loader: - kv  16:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  17:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_0:  225 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.8000 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q4_0\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 4.33 GiB (4.64 BPW) \n",
      "llm_load_print_meta: general.name     = Models\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  4437.80 MiB\n",
      ".......................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 10016\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 500000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  1252.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1252.00 MiB, K (f16):  626.00 MiB, V (f16):  626.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   677.57 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '8192', 'general.name': 'Models', 'general.type': 'model', 'general.size_label': '8.0B', 'general.license': 'llama3', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: llama-3\n",
      "A new version of the following files was downloaded from https://huggingface.co/dunzhang/stella_en_400M_v5:\n",
      "- configuration.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/dunzhang/stella_en_400M_v5:\n",
      "- modeling.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Some weights of the model checkpoint at dunzhang/stella_en_400M_v5 were not used when initializing NewModel: ['new.pooler.dense.bias', 'new.pooler.dense.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_url = \"https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q4_0.gguf\"\n",
    "llm_llama3 = LlamaCPP(\n",
    "    model_url=model_url,\n",
    "    model_path=None,\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=512,\n",
    "    context_window=10000,\n",
    "    generate_kwargs={},\n",
    "    model_kwargs={\"n_gpu_layers\": 2},\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "Settings.llm = llm_llama3\n",
    "Settings.chunk_size = 512\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name = \"dunzhang/stella_en_400M_v5\", device = \"cuda\", trust_remote_code=True, embed_batch_size=20)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wikitext(split=\"train\"):\n",
    "    dataset = load_dataset(\"Salesforce/wikitext\", \"wikitext-103-raw-v1\")\n",
    "    \n",
    "    documents = []\n",
    "    current_doc = \"\"\n",
    "    current_title = \"\"\n",
    "    \n",
    "    for item in dataset[split]:\n",
    "        text = item['text']\n",
    "        if text.startswith(\" = \") and text.endswith(\" = \\n\") and not text.startswith(\" = = \"):\n",
    "            if current_doc != \"\":\n",
    "                documents.append(Document(text=current_doc, metadata={\"title\": current_title}))\n",
    "            current_title = text\n",
    "            current_doc = \"\"\n",
    "        else:\n",
    "           current_doc += text + \"\\n\"\n",
    "    \n",
    "    if current_doc:\n",
    "        documents.append(Document(text=current_doc, metadata={\"title\": current_title}))\n",
    "    \n",
    "    return documents\n",
    "\n",
    "wikitext_docs = load_wikitext()\n",
    "print(f\"Loaded {len(wikitext_docs)} documents from WikiText\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'@-@', '-', text)  # Replace @-@ with actual hyphens\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove other @ annotations\n",
    "    text = re.sub(r'\\n+', '\\n', text)  # Replace multiple newlines with a single one\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+\\.', '.', text)  # Remove spaces before periods\n",
    "    text = re.sub(r'\\s+,', ',', text)  # Remove spaces after commas\n",
    "    text = re.sub(r'\\s+:', ':', text)  # Remove spaces before colons\n",
    "    text = re.sub(r'\\s+\\'', '\\'', text)  # Remove spaces before '\n",
    "    return text.strip()\n",
    "\n",
    "for doc in wikitext_docs[:10]:\n",
    "    doc.text = clean_text(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " = Valkyria Chronicles III = \n",
      "\n",
      "Senjō no Valkyria 3: Unrecorded Chronicles ( Japanese: 戦場のヴァルキュリア3 ,lit. Valkyria of the Battlefield 3 ) ,commonly referred to as Valkyria Chronicles III outside Japan ,is a tactical role - playing video game developed by Sega and Media.Vision for the PlayStation Portable. Released in January 2011 in Japan ,it is the third game in the Valkyria series. Employing the same fusion of tactical and real - time gameplay as its predecessors ,the story runs parallel to the first game and follows the \" Nameless \" ,a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \". The game began development in 2010 ,carrying over a large portion of the work done on Valkyria Chronicles II. While it retained the standard features of the series ,it also underwent multiple adjustments ,such as making the game more forgiving for series newcomers. Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries ,along with Valkyria Chronicles II director Takeshi Ozawa. A large team of writers handled the script. The game's opening theme was sung by May'n. It met with positive sales in Japan ,and was praised by both Japanese and western critics. After release ,it received downloadable content ,along with an expanded edition in November of that year. It was also adapted into manga and an original video animation series. Due to low sales of Valkyria Chronicles II ,Valkyria Chronicles III was not localized ,but a fan translation compatible with the game's expanded edition was released in 2014. Media.Vision would return to the franchise with the development of Valkyria: Azure Revolution for the PlayStation 4. = = Gameplay = = As with previous Valkyira Chronicles games ,Valkyria Chronicles III is a tactical role - playing game where players take control of a military unit and take part in missions against enemy forces. Stories are told through comic book - like panels with animated character portraits ,with characters speaking partially through voiced speech bubbles and partially through unvoiced text. The player progresses through a series of linear missions ,gradually unlocked as maps that can be freely scanned through and replayed as they are unlocked. The route to each story location on the map varies depending on an individual player's approach: when one option is selected ,the other is sealed off to the player. Outside missions ,the player characters rest in a camp ,where units can be customized and character growth occurs. Alongside the main story missions are character - specific sub missions relating to different squad members. After the game's completion ,additional episodes are unlocked ,some of them having a higher difficulty than those found in the rest of the game. There are also love simulation elements related to the game's two main heroines ,although they take a very minor role. The game's battle system ,the BliTZ system ,is carried over directly from Valkyira Chronicles. During missions ,players select each unit using a top - down perspective of the battlefield map: once a character is selected ,the player moves the character around the battlefield in third - person. A character can only act once per - turn ,but characters can be granted multiple turns at the expense of other characters' turns. Each character has a field and distance of movement limited by their Action Gauge. Up to nine characters can be assigned to a single mission. During gameplay ,characters will call out if something happens to them ,such as their health points ( HP ) getting low or being knocked out by enemy attacks. Each character has specific \" Potentials \" ,skills unique to each character. They are divided into \" Personal Potential \" ,which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character ,and \" Battle Potentials \" ,which are grown throughout the game and always grant boons to a character. To learn Battle Potentials ,each character has a unique \" Masters Table \" ,a grid - based skill table that can be used to acquire and link different skills. Characters also have Special Abilities that grant them temporary boosts on the battlefield: Kurt can activate \" Direct Command \" and move around the battlefield without depleting his Action Point gauge ,the character Reila can shift into her \" Valkyria Form \" and become invincible ,while Imca can target multiple enemy units with her heavy weapon. Troops are divided into five classes: Scouts ,Shocktroopers ,Engineers ,Lancers and Armored Soldier. Troopers can switch classes by changing their assigned weapon. Changing class does not greatly affect the stats gained while in a previous class. With victory in battle ,experience points are awarded to the squad ,which are distributed into five different attributes shared by the entire squad ,a feature differing from early games' method of distributing to different unit types. = = Plot = = The game takes place during the Second Europan War. Gallian Army Squad 422 ,also known as \" The Nameless \" ,are a penal military unit composed of criminals ,foreign deserters ,and military offenders whose real names are erased from the records and thereon officially referred to by numbers. Ordered by the Gallian military to perform the most dangerous missions that the Regular Army and Militia will not do ,they are nevertheless up to the task ,exemplified by their motto ,Altaha Abilia ,meaning \" Always Ready. \" The three main characters are No.7 Kurt Irving ,an army officer falsely accused of treason who wishes to redeem himself ; Ace No.1 Imca ,a female Darcsen heavy weapons specialist who seeks revenge against the Valkyria who destroyed her home ; and No.13 Riela Marcellis ,a seemingly jinxed young woman who is unknowingly a descendant of the Valkyria. Together with their fellow squad members ,these three are tasked to fight against a mysterious Imperial unit known as Calamity Raven ,consisting of mostly Darcsen soldiers. As the Nameless officially do not exist ,the upper echelons of the Gallian Army exploit the concept of plausible deniability in order to send them on missions that would otherwise make Gallia lose face in the war. While at times this works to their advantage ,such as a successful incursion into Imperial territory ,other orders cause certain members of the 422nd great distress. One such member ,Gusurg ,becomes so enraged that he abandons his post and defects into the ranks of Calamity Raven ,attached to the ideal of Darcsen independence proposed by their leader ,Dahau. At the same time ,elements within Gallian Army Command move to erase the Nameless in order to protect their own interests. Hounded by both allies and enemies ,and combined with the presence of a traitor within their ranks ,the 422nd desperately move to keep themselves alive while at the same time fight to help the Gallian war effort. This continues until the Nameless's commanding officer ,Ramsey Crowe ,who had been kept under house arrest ,is escorted to the capital city of Randgriz in order to present evidence exonerating the weary soldiers and expose the real traitor ,the Gallian General that had accused Kurt of Treason. Partly due to these events ,and partly due to the major losses in manpower Gallia suffers towards the end of the war with the Empire ,the Nameless are offered a formal position as a squad in the Gallian Army rather than serve as an anonymous shadow force. This is short - lived ,however ,as following Maximilian's defeat ,Dahau and Calamity Raven move to activate an ancient Valkyrian super weapon within the Empire ,kept secret by their benefactor. Without the support of Maximilian or the chance to prove themselves in the war with Gallia ,it is Dahau's last trump card in creating a new Darcsen nation. As an armed Gallian force invading the Empire just following the two nations' cease - fire would certainly wreck their newfound peace ,Kurt decides to once again make his squad the Nameless ,asking Crowe to list himself and all under his command as killed - in - action. Now owing allegiance to none other than themselves ,the 422nd confronts Dahau and destroys the Valkyrian weapon. Each member then goes their separate ways in order to begin their lives anew. = = Development = = Concept work for Valkyria Chronicles III began after development finished on Valkyria Chronicles II in early 2010 ,with full development beginning shortly after this. The director of Valkyria Chronicles II ,Takeshi Ozawa ,returned to that role for Valkyria Chronicles III. Development work took approximately one year. After the release of Valkyria Chronicles II ,the staff took a look at both the popular response for the game and what they wanted to do next for the series. Like its predecessor ,Valkyria Chronicles III was developed for PlayStation Portable: this was due to the team wanting to refine the mechanics created for Valkyria Chronicles II ,and they had not come up with the \" revolutionary \" idea that would warrant a new entry for the PlayStation 3. Speaking in an interview ,it was stated that the development team considered Valkyria Chronicles III to be the series' first true sequel: while Valkyria Chronicles II had required a large amount of trial and error during development due to the platform move ,the third game gave them a chance to improve upon the best parts of Valkyria Chronicles II due to being on the same platform. In addition to Sega staff from the previous games ,development work was also handled by Media.Vision. The original scenario was written Kazuki Yamanobe ,while the script was written by Hiroyuki Fujii ,Koichi Majima ,Kishiko Miyagi ,Seiki Nagakawa and Takayuki Shouji. Its story was darker and more somber than that of its predecessor. The majority of material created for previous games ,such as the BLiTZ system and the design of maps ,was carried over. Alongside this ,improvements were made to the game's graphics and some elements were expanded ,such as map layouts ,mission structure ,and the number of playable units per mission. A part of this upgrade involved creating unique polygon models for each character's body. In order to achieve this ,the cooperative elements incorporated into the second game were removed ,as they took up a large portion of memory space needed for the improvements. They also adjusted the difficulty settings and ease of play so they could appeal to new players while retaining the essential components of the series' gameplay. The newer systems were decided upon early in development. The character designs were done by Raita Honjou ,who had worked on the previous Valkyria Chronicles games. When creating the Nameless Squad ,Honjou was faced with the same problem he had had during the first game: the military uniforms essentially destroyed character individuality ,despite him needing to create unique characters the player could identify while maintaining a sense of reality within the Valkyria Chronicles world. The main color of the Nameless was black. As with the previous Valkyria games ,Valkyria Chronicles III used the CANVAS graphics engine. The anime opening was produced by Production I.G. = = = Music = = = The music was composed by Hitoshi Sakimoto ,who had also worked on the previous Valkyria Chronicles games. When he originally heard about the project ,he thought it would be a light tone similar to other Valkyria Chronicles games ,but found the themes much darker than expected. An early theme he designed around his original vision of the project was rejected. He redid the main theme about seven times through the music production due to this need to reassess the game. The main theme was initially recorded using orchestra ,then Sakimoto removed elements such as the guitar and bass ,then adjusted the theme using a synthesizer before redoing segments such as the guitar piece on their own before incorporating them into the theme. The rejected main theme was used as a hopeful tune that played during the game's ending. The battle themes were designed around the concept of a \" modern battle \" divorced from a fantasy scenario by using modern musical instruments ,constructed to create a sense of atonality. While Sakimoto was most used to working with synthesized music ,he felt that he needed to incorporate live instruments such as orchestra and guitar. The guitar was played by Mitsuhiro Ohta ,who also arranged several of the later tracks. The game's opening theme song ,\" If You Wish for... \" ( もしも君が願うのなら ,Moshimo Kimi ga Negauno Nara ) ,was sung by Japanese singer May'n. Its theme was the reason soldiers fought ,in particular their wish to protect what was precious to them rather than a sense of responsibility or duty. Its lyrics were written by Seiko Fujibayashi ,who had worked on May'n on previous singles. = = = Release = = = In September 2010 ,a teaser website was revealed by Sega ,hinting at a new Valkyria Chronicles game. In its September issue ,Famitsu listed that Senjō no Valkyria 3 would be arriving on the PlayStation Portable. Its first public appearance was at the 2010 Tokyo Game Show ( TGS ) ,where a demo was made available for journalists and attendees. During the publicity ,story details were kept scant so as not to spoil too much for potential players ,along with some of its content still being in flux at the time of its reveal. To promote the game and detail the story leading into the game's events ,an episodic Flash visual novel written by Fujii began release in January 2011. The game was released January 27 ,2011. During an interview ,the development team said that the game had the capacity for downloadable content ( DLC ) ,but that no plans were finalized. Multiple DLC maps ,featuring additional missions and recruitable characters ,were released between February and April 2011. An expanded edition of the game ,Valkyria Chronicles III Extra Edition ,released on November 23 ,2011. Packaged and sold at a lower price than the original ,Extra Edition game with seven additional episodes: three new ,three chosen by staff from the game's DLC ,and one made available as a pre - order bonus. People who also owned the original game could transfer their save data between versions. Unlike its two predecessors ,Valkyria Chronicles III was not released in the west. According to Sega ,this was due to poor sales of Valkyria Chronicles II and the general unpopularity of the PSP in the west. An unofficial fan translation patch began development in February 2012: players with a copy of Valkyria Chronicles III could download and apply the patch ,which translated the game's text into English. Compatible with the Extra Edition ,the patch was released in January 2014. = = Reception = = On its day of release in Japan ,Valkyria Chronicles III topped both platform - exclusive and multi - platform sales charts. By early February ,the game sold 102 @,@ 779 units ,coming in second overall to The Last Story for the Wii. By the end of the year ,the game had sold just over 152 @,@ 500 units. Famitsu enjoyed the story ,and were particularly pleased with the improvements to gameplay. Japanese gaming site Game Watch Impress ,despite negatively noting its pacing and elements recycled from previous games ,was generally positive about its story and characters ,and found its gameplay entertaining despite off - putting difficulty spikes. 4Gamer.net writer Naohiko Misuosame ,in a \" Play Test \" article based on the game's PSN demo ,felt that Valkyria Chronicles III provided a \" profound feeling of closure \" for the Valkyria Chronicles series. He praised its gameplay despite annoying limitations to aspects such as special abilities ,and positively noted its shift in story to a tone similar to the first game. PlayStation Official Magazine - UK praised the story's blurring of Gallia's moral standing ,art style ,and most points about its gameplay ,positively noting the latter for both its continued quality and the tweaks to balance and content. Its one major criticism were multiple difficulty spikes ,something that had affected the previous games. Heath Hindman of gaming website PlayStation Lifestyle praised the addition of non - linear elements and improvements or removal of mechanics from Valkyria Chronicles II in addition to praising the returning gameplay style of previous games. He also positively noted the story's serious tone. Points criticized in the review were recycled elements ,awkward cutscenes that seemed to include all characters in a scene for no good reason ,pacing issues ,and occasional problems with the game's AI. In a preview of the TGS demo ,Ryan Geddes of IGN was left excited as to where the game would go after completing the demo ,along with enjoying the improved visuals over Valkyria Chronicles II. Kotaku's Richard Eisenbeis was highly positive about the game ,citing is story as a return to form after Valkyria Chronicles II and its gameplay being the best in the series. His main criticisms were its length and gameplay repetition ,along with expressing regret that it would not be localized. = = Legacy = = Kurt and Riela were featured in the Nintendo 3DS crossover Project X Zone ,representing the Valkyria series. Media.Vision would return to the series to develop Valkyria: Azure Revolution ,with Ozawa returning as director. Azure Revolution is a role - playing video game for the PlayStation 4 that forms the beginning of a new series within the Valkyria franchise. = = = Adaptations = = = Valkyria Chronicles 3 was adapted into a two - episode original video animation series in the same year of its release. Titled Senjō no Valkyria 3: Taga Tame no Jūsō ( 戦場のヴァルキュリア３ 誰がための銃瘡 ,lit. Valkyria of the Battlefield 3: The Wound Taken for Someone's Sake ) ,it was originally released through PlayStation Network and Qriocity between April and May 2011. The initially - planned release and availability period needed to be extended due to a stoppage to PSN during the early summer of that year. It later released for DVD on June 29 and August 31 ,2011 ,with separate \" Black \" and \" Blue \" editions being available for purchase. The anime is set during the latter half of Valkyria Chronicles III ,detailing a mission by the Nameless against their Imperial rivals Calamity Raven. The anime was first announced in November 2010. It was developed by A - 1 Pictures ,produced by Shinji Motoyama ,directed by Nobuhiro Kondō ,and written by Hiroshi Ōnogi. Sakimoto's music for the game was used in the anime. The anime's title was inspired by the principle purpose of the Nameless: to suffer in battle for the goals of others. A subtitle attached to the project during development was \" The Road to Kubinka \" ,which referenced the Kubinka Tank Museum in Moscow. The game's main theme was how the characters regained their sense of self when stripped of their names and identities ,along with general themes focused on war and its consequences. While making the anime ,the production team were told by Sega to make it as realistic as possible ,with the consequence that the team did extensive research into aspects such as what happened when vehicles like tanks were overturned or damaged. Due to it being along the same timeline as the original game and its television anime adaptation ,the cast of Valkyria Chronicles could make appearances ,which pleased the team. The opening theme ,\" Akari ( Light ) -Tomoshibi- \" ( 灯 - TOMOSHIBI- ) ,was sung by Japanese singer Faylan. The ending theme ,\" Someday the Flowers of Light Will Bloom \" ( いつか咲く光の花 ,Itsuka Saku Hikari no Hana ) ,was sung by Minami Kuribayashi. Both songs' lyrics were written by their respective artists. Two manga adaptations were produced ,following each of the game's main female protagonists Imca and Riela. They were Senjō no Valkyria 3: Namo naki Chikai no Hana ( 戦場のヴァルキュリア3 名もなき誓いの花 ,lit. Valkyria of the Battlefield 3: The Flower of the Nameless Oath ) ,illustrated by Naoyuki Fujisawa and eventually released in two volumes after being serialized in Dengeki Maoh between 2011 and 2012 ; and Senjō no Valkyria 3: -Akaki Unmei no Ikusa Otome- ( 戦場のヴァルキュリア3 -赤き運命の戦乙女- ,lit. Valkyria of the Battlefield 3 -The Valkyrie of the Crimson Fate ) ,illustrated by Mizuki Tsuge and eventually released in a single volume by Kadokawa Shoten in 2012.\n",
      "\n",
      " = Tower Building of the Little Rock Arsenal = \n",
      "\n",
      "The Tower Building of the Little Rock Arsenal ,also known as U.S. Arsenal Building ,is a building located in MacArthur Park in downtown Little Rock ,Arkansas. Built in 1840 ,it was part of Little Rock's first military installation. Since its decommissioning ,The Tower Building has housed two museums. It was home to the Arkansas Museum of Natural History and Antiquities from 1942 to 1997 and the MacArthur Museum of Arkansas Military History since 2001. It has also been the headquarters of the Little Rock Æsthetic Club since 1894. The building receives its name from its distinct octagonal tower. Besides being the last remaining structure of the original Little Rock Arsenal and one of the oldest buildings in central Arkansas ,it was also the birthplace of General Douglas MacArthur ,who became the supreme commander of US forces in the South Pacific during World War II. It was also the starting place of the Camden Expedition. In 2011 it was named as one of the top 10 attractions in the state of Arkansas by Arkansas.com. = = Construction = = The arsenal was constructed at the request of Governor James Sevier Conway in response to the perceived dangers of frontier life and fears of the many Native Americans who were passing through the state on their way to the newly established Oklahoma Territory. Thirty - six acres were appropriated on the outskirts of Little Rock by Major Robert B. Lee of the U.S. Army. The land had been previously used as a racetrack by the local jockey club. John Wormley Walker ,a builder for the Federal Government ,supervised the construction. Originally $ 14 @,@ 000 was allocated for the construction of the arsenal ,but proved inadequate. The budget was later increased to $ 30 @,@ 000. Work began on the Tower Building in 1840 ,and it was the first permanent structure of the arsenal to be built. Being originally constructed to store ammunition ,the building was designed with 3 - foot - thick ( 0 @.@ 91 m ) exterior walls. The original plans called for it to be built of stone ,however ,masonry was used instead. The Arkansas Gazette referred to the structure as \" A splendid specimen of masonry \". = = Civil War = = For several years the arsenal ,which was owned by the federal government ,served as a simple arms depot and was staffed with only a handful of soldiers. But in November 1860 ,with the American Civil War on the horizon ,a company of the Second United States Artillery ,consisting of sixty - five men ,was transferred to Little Rock under the command of Captain James Totten. On January 15 ,1861 ,the state legislature decided to hold a referendum to determine if a state convention should be held to consider the issue of secession and to elect delegates to such a convention. It was planned for February 18 ; however ,events at the arsenal ,would not wait. On January 28 ,then Governor Henry Massey Rector informed Captain Totten that he and his soldiers would be \" permitted to remain in the possession of the Federal officers until the State ,by authority of the people ,shall have determined to sever their connection with the General Government ,\" Totten responded to this by telling the Governor that his orders came from the United States Government and began a desperate but ultimately futile dispatch of letters and telegrams asking for reinforcements ,although rumors were widely spread that they were already coming. The first telegraph wire to span between Little Rock and Memphis had recently been completed. Local attorney John M Harrel was asked to compose the first telegraph dispatched from Arkansas's capital. In his message ,Harrel reported unconfirmed rumors that more federal troops had been sent to reinforce the Little Rock Arsenal. The United States troops at the outposts of the western frontier of the state and in the Indian nation have all been recalled from winter quarters to reinforce the garrison at Fort Smith. The garrison at Fort Smith had been previously transferred to the United States Arsenal in this city ( Little Rock ). The arsenal is one of the richest depositories of military stores in the United States and is supposed to be the ultimate destination of the tropps [ sic ] ordered from the frontier. -John M Harrel Telegram ,January 31 ,1861 The item was intended simply as a piece of news ,but telegraph lines quickly spread the news throughout the state ,fueling procession sentiment. The rumor was interpreted by some Arkansans as a call from the governor to assemble to help expel the federal troops from the arsenal. By February 5 ,six militia units ,consisting of 1 @,@ 000 men ,with a guarantee that the numbers could be increased to 5 @,@ 000 if the situations deemed it necessary ,had assembled in Little Rock. Governor Rector vehemently denied ordering the troops to assemble or giving any order at all in connection with the troops. Faced with the fact that the military had assembled believing they were following his orders and the consensus of the citizens of Little Rock against any armed conflict between the civilian army and federal troops ,Governor Rector was forced to take control of the situation. On February 6 ,he sent a formal demand for surrender of the arsenal to Captain Totten ,This movement is prompted by the feeling that pervades the citizens of this State that in the present emergency the arms and munitions of war in the Arsenal should be under the control of the State authorities ,in order to their security. This movement ,although not authorized by me ,has assumed such an aspect that it becomes my duty ,as the executive of this Sate ,to interpose my official authority to prevent a collision between the people of the State and the Federal troops under your command. I therefore demand in the name of the State the delivery of the possession of the Arsenal and munitions of war under your charge to the State authorities ,to be held subject to the action of the convention to be held on the 4th of March next. Perhaps because Abraham Lincoln had not yet been inaugurated as President ,Captain Totten received no instructions from his superiors and was forced to withdraw his troops. He agreed to surrender the arsenal as long as the governor agreed to three provisions: The governor would take possession of the arsenal in the name of the United States. The soldiers would be allowed safe passage in any direction carrying any personal and public property besides munitions of war. The soldiers would be allowed to march away as men leaving under orders ,not as conquered and surrendering soldiers. On the morning of February 8 ,1861 ,Rector and Totten signed an agreement placing the arsenal in the hands of state officials. That afternoon ,the citizen militia marched to the arsenal with Governor Rector at its head. All of the federal troops had left at this point ,except Totten who had stayed behind to listen to the Governor's speech and to hand the arsenal over in person. The Little Rock Arsenal was classified in 1860 as an \" arsenal of deposit ,\" meaning that it was simply a warehouse for the storage of weapons intended for the use of the state militia in times of crisis. Thus there were no substantial operations for ordnance fabrication or repairs ,nor for the manufacture of cartridges at the time the Arsenal fell into State hands. Most of these operations were started from scratch through the efforts of the Arkansas Military Board. Inside the Little Rock Arsenal after its seizure in February ,1861 ,the Confederates inventoried some 10 @,@ 247 weapons ,250 @,@ 000 musket cartridges ,and 520 @,@ 000 percussion caps ,as well as the four bronze cannon of Totten's battery. Long arms in the Arsenal's inventory consisted of: M1822.69 cal ( flintlock ) 5 @,@ 625 M1822.69 cal ( percussion - converted ) 53 M1842.69 cal smoothbore ( percussion ) 357 M1855.58 cal rifle - muskets 900 M1817 common rifles 125 M1841 rifle ( \" Mississippi Rifle \" ) 54 M1847 musketoon 2 Hall's carbines 267 Hall's rifles ( flintlock ) 2 @,@ 864 Total 10 @,@ 247 Of this number ,approximately 9600 weapons were serviceable ,or ready - for - issue. Note there were only 1 @,@ 364 percussion weapons available. Disposition of the weapons found in the Arsenal is somewhat sketchy ,but from various records it can be surmised that the 5th ,6th ,7th ,and 8th Arkansas Infantry Regiments ,mustered in June ,1861 ,were issued M1816 / M1822.69 caliber flintlocks. The 9th and 10th Arkansas ,four companies of Kelly's 9th Arkansas Battalion ,and the 3rd Arkansas Cavalry Regiment were issued flintlock Hall's Rifles. The units comprising the infantry force of Van Dorn's Army of the West were the 1st and 2nd Arkansas Mounted Rifles were also armed with M1822 flintlocks from the Little Rock Arsenal. By the time the 11th and 12th Arkansas Infantry Regiments mustered in at Little Rock ,the supply of arms had been almost completely exhausted ,and only old \" junker \" weapons were left. Most of the equipment ,arms ,and machinery at the Little Rock Arsenal was removed to east of the Mississippi River by order of Maj. Gen. Earl Van Dorn in April and May 1862 ,and accountability for it is lost at that point. By all appearances ,the equipment was sent down the river to Napoleon ,Arkansas ,and from there to Jackson Mississippi ,where it was probably destroyed during the Vicksburg campaign in the early summer of 1863. Major General Thomas C. Hindman ,sent to command the district of Arkansas in May ,1862 ,found the state nearly destitute of military material. Hindman established another armory at Arkadelphia ,and revived the Little Rock Arsenal as a collection point and depot for armaments and ammunition manufacture for small arms. Hindman recorded: \" Machinery was made for manufacturing percussion caps and small arms ,and both were turned out in small quantity ,but of excellent quality. Lead mines were opened and worked ,and a chemical laboratory was established and successfully operated in aid of the Ordnance Department and in the manufacture of calomel ,castor oil ,spirits of nitre ,the various tinctures of iron ,and other valuable medicines. Most of these works were located at or near Arkadelphia on the Ouachita River ,75 miles south from Little Rock. The tools ,machinery ,and the material were gathered piecemeal or else made by hand labor. Nothing of this sort had been before attempted on Government account in Arkansas to my knowledge ,except for the manufacture of small arms ,the machinery for which was taken away by General Van Dorn and there was neither capital nor sufficient enterprise among the citizens to engage in such undertakings � A further supply ,along with lead and caps ,was procured from the citizens of Little Rock and vicinity by donation ,purchases ,and impressments. This ammunition ,and that which I brought with me ,was rapidly prepared for use at the Laboratory established at the Little Rock Arsenal for that purpose. As illustrating as the pitiful scarcity of material in the country ,the fact may be stated that it was found necessary to use public documents of the State Library for cartridge paper. Gunsmiths were employed or conscripted ,tools purchased or impressed ,and the repair of the damaged guns I brought with me and about an equal number found at Little Rock commenced at once. But ,after inspecting the work and observing the spirit of the men I decided that a garrison 500 strong could hold out against Fitch and that I would lead the remainder - about 1500 - to Gen'l Rust as soon as shotguns and rifles could be obtained from Little Rock instead of pikes and lances ,with which most of them were armed. Two days elapsed before the change could be effected. \" The Confederate ordnance establishment at Little Rock was reactivated in August ,1862. Looking around for a suitable person to head this activity ,General Hindman turned to the Confederate Navy and borrowed Lieutenant John W. Dunnington. Lt. Dunnington was the commander of the gunboat C.S.S. Ponchartrain ,which had been brought to Little Rock in hopes of converting it to an ironclad. Dunnington was selected to head the ordnance works at Little Rock ,and although he continued to draw his pay from the Confederate Navy Department ,he was placed in charge of all Confederate ordnance activities ( which included artillery functions ) there with the rank of lieutenant colonel. Lt. Col. Dunnington's \" Returns for the month of August ,1862 ,at Little Rock Arsenal ,C.S.A. ,\" are found in Vol. 149 ,Chapter IV of the \" Captured Rebel Ordnance Records ,\" and are most enlightening as to the scope of Confederate ordnance activities at Little Rock during this crucial time. According to Dunnington ,\" When I assumed command at this Post ,all material had been removed to Arkadelphia. There were no persons employed. No shops were open for repair of arms or for fabricating ammunition. Material ,tools ,etc. ,had to be procured as well as the employment of laborers. Work commenced the last part of the month. \" The military force at Little Rock under Dunnington's command consisted of four officers: himself ,Major John B. Lockman ,Captain C.C. Green ,and 2nd Lt. W.W. Murphy. In addition to these ,he had 20 enlisted men and a civilian force composed of a foreman ,2 clerks ,3 gunsmiths for repairing small arms ,a laboratorian ,26 laborers in the ammunition laboratory ,and a carpenter for making packing boxes. During the month of August ,1862 ,the following work was performed: \" Fabricated: one pair of musket bullet moulds ; 10 @,@ 000 buck & ball shot cartridges ; repaired: 750 muskets ,shotguns ,and rifles ; received and repaired: ordnance stores and ordnances ; performed: guard ,office ,and police duties ; inspected: Posts at Camden and Arkadelphia. \" Lt. Col. Dunnington continued to build up his works at Little Rock until November 1862 ,when Captain Sanford C. Faulkner ( composer of The Arkansas Traveler ) was placed in charge of the Arsenal. Dunnington presumably returned to his naval duties and the Ponchartrain. A \" Summary of the Work Done for November ,1862 ,Little Rock Arsenal \" shows: Fabrication: 75 @,@ 000 buck & ball cartridges - percussion 14 @,@ 000 buck & ball cartridges - flint 275 paper fuzes 117 rounds ,6 - pounder canister shot 130 rounds ,6 - pounder ball shot 96 ammunition packing boxes Repaired: 2 @,@ 236 shotguns and rifles ( repaired mostly for troops in service ) 23 pistols ( repaired mostly for troops in service ) Received & Issued: 752 packages of ordnance and ordnance stores received and mostly issued to troops in service. Repaired and painted: 4 gun carriages Performed: Guard ,office ,and police duties. Perhaps the most illuminating points of the above \" Summary of Work \" and those for following months are that the standard ammunition made was. \" buck & ball \" ,indicating that the.69 caliber smoothbores and shotguns remained the predominant caliber weapon in use ,and of this ,nearly one sixth or more of all small arms ammunition was still for flintlock weapons ,indicating that no less than a sixth of the Confederate troops in this vicinity were still armed with obsolete flintlock weapons. The \" Summaries of Work done at Little Rock Arsenal ,C.S.A. \" continue at about the same pace and scale from August 1862 until August 1863. Appended to the \" Summary \" for August ,1863 is the ominous notation ,\" During the last week in the month ,nearly all stores at the Arsenal have been packed and sent to Arkadelphia ,in obedience to orders from Chief of Ordnance ,District of Arkansas. \" This then marks the beginning of the evacuation of ordnance activities from Little Rock ,with the city being surrendered to the advancing Federal troops of Frederick Steele's Arkansas Expedition on September 11 ,1863. In 1864 ,after Little Rock fell to the Union Army and the arsenal had been recaptured ,General Fredrick Steele marched 8 @,@ 500 troops from the arsenal beginning the Camden Expedition. The arsenal was briefly seized once more by Joseph Brooks loyalists during the Brooks - Baxter War of 1874. = = Decommissioning = = In 1873 ,the building was renamed Little Rock Barracks and used as a barracks for married officers and their families. The building was drastically altered the inside and outside. Prior to renovation ,a rear basement door provided the only entrance to the building ,while the tower served as a hoist to move munitions between floors. By 1868 ,front and rear porches had been added to the building ,as well as interior walls and stairs ,some of which remain today ,including the central staircase. In 1880 ,Douglas MacArthur was born on the northwest upper floor of this building while his father ,Captain Arthur MacArthur ,was stationed there. In the 1880s ,the federal government began closing many small arsenals around the country in favor of smaller ones built near railroads for quick deployment. The arsenal commander received word from Washington that the Little Rock site must be abandoned \" not later than October 1 ,1890. \" On April 12 ,1893 the tower building and the surrounding buildings were traded to the city of Little Rock for 1 @,@ 000 acres ( 4 km ² ) in North Little Rock under the condition that the building and land be \" forever exclusively devoted to the uses and purposes of a public park \" for 1 @,@ 000 acres ( 4 km ² ) in Big Rock Mountain on the north side of the Arkansas River ,present day North Little Rock. That site later became Fort Logan H. Roots. All of the original buildings surrounding the Tower Building were demolished. = = Æsthetic Club = = In 1894 the Little Rock Æsthetic Club ,one of the oldest women's societies west of the Mississippi River ,moved into the Tower Building. This was prompted due to increased membership and a need for larger ,more permanent quarters. The previous year ,club members working with women's organizations throughout the state ,raised money to furnish the Arkansas Building of the Columbian Exposition at The Chicago World's Fair. At the fair's conclusion ,artifacts from the exhibit were displayed in the Tower Building ,with the Æsthetic Club invited to meet in the \" Columbian Room. \" Except for Æsthetic Club meetings ,the Tower Building remained largely unoccupied for almost fifty years and suffered significant deterioration. The Æsthetic Club provided much - needed financial support during the period and even paid the electric bill during the Great Depression. The Æsthetic Club is still headquartered in the Tower Building. = = Public use = = The building and the surrounding park were used for many public purposes throughout the early 20th century. The Tower Building served as headquarters for the United Confederate Veterans Reunion ,May 15 – 18 ,1911. Over 106 @,@ 000 Civil War veterans ,the largest popular gathering in the history of the city up to that time ,attended and were housed in the building or camped in the park ,which had also become a popular camping area. Later the building served as an armory for the Arkansas National Guard. In 1912 ,the second floor of the Tower Building became Little Rock's first public library. In 1917 ,Little Rock built a fire station in the park ,that building is now gone. A band shell named for H. H. Foster also was built in the park during this time ,but also no longer exists. In 1936 ,Works Progress Administration built the Museum of Fine Arts ,now called the Arkansas Arts Center ,just south of the Tower Building. The arsenal was listed in the National Register of Historic Places in 1970. Due to its association with the Camden Expedition of 1864 ,the arsenal may be included in the Camden Expedition Sites National Historic Landmark designated in 1994. In 1942 ,the Tower Building was renovated due to the efforts of the Æsthetic Club ,Little Rock philanthropist Frederick W. Allsop ,and the Works Progress Administration. It became the new home of The Arkansas Museum of Natural History and Antiquities ,which had been located in Little Rock City Hall. The museum remained in the tower building for approximately fifty - five years. The area surrounding the Tower Building had been known as Arsenal Park when the first decommissioned and then later renamed City Park. Due to the efforts of Bernie Babcock ,however ,the city finally named it MacArthur Park in 1942 in honor of Douglas MacArthur. In 1997 ,the Museum of Science and Natural History merged with the Little Rock Children's Museum ,which had been located in Union Station ,to form the Arkansas Museum of Discovery. The new museum was relocated to a historic building in the Little Rock River Market District. The MacArthur Museum of Arkansas Military History opened on May 19 ,2001 in the Tower Building. The new museum's goal is to educate and inform visitors about the military history of Arkansas ,preserve the Tower Building ,honor servicemen and servicewomen of the United States and commemorate the birthplace of Douglas MacArthur.\n",
      "\n",
      " = Cicely Mary Barker = \n",
      "\n",
      "Cicely Mary Barker ( 28 June 1895 – 16 February 1973 ) was an English illustrator best known for a series of fantasy illustrations depicting fairies and flowers. Barker's art education began in girlhood with correspondence courses and instruction at the Croydon School of Art. Her earliest professional work included greeting cards and juvenile magazine illustrations ,and her first book ,Flower Fairies of the Spring ,was published in 1923. Similar books were published in the following decades. Barker was a devout Anglican ,and donated her artworks to Christian fundraisers and missionary organizations. She produced a few Christian - themed books such as The Children ’ s Book of Hymns and ,in collaboration with her sister Dorothy ,He Leadeth Me. She designed a stained glass window for St. Edmund's Church ,Pitlake ,and her painting of the Christ Child ,The Darling of the World Has Come ,was purchased by Queen Mary. Barker was equally proficient in watercolour ,pen and ink ,oils ,and pastels. Kate Greenaway and the Pre - Raphaelites were the principal influences on her work. She claimed to paint instinctively and rejected artistic theories. Barker died in 1973. Though she published Flower Fairy books with spring ,summer ,and autumn themes ,it wasn't until 1985 that a winter collection was assembled from her remaining work and published posthumously. = = Biography = = = = = Early life = = = Barker was born the second daughter and youngest child of Walter Barker ,a partner in a seed supply company and an amateur artist ,and his wife Mary Eleanor ( Oswald ) Barker on 28 June 1895 at home at 66 Waddon Road in Croydon ,Surrey ,England. Barker was an epileptic as a child ,and cared for at home by her parents. Later ,her sister and elder by two years ,Dorothy Oswald Barker ,continued the care. The family of four was moderately well off ,and belonged to the lower end of the upper middle class. A nanny ,a governess ,and a cook to prepare special meals for Barker were hired. She spent much time in bed at home amusing herself with painting books and a nursery library that included the works of Kate Greenaway and Randolph Caldecott – two artists who exerted strong influences on her later art. = = = Art education and first professional work = = = Barker took correspondence courses in art ,probably until about 1919. In 1908 at 13 years ,she entered an evening class at the Croydon School of Art ,and attended the school into the 1940s. In time ,she received a teaching position. In 1911 ,Raphael Tuck & Sons bought four of Barker's \" little drawings \" for half a sovereign ,and published them as postcards. In October 1911 ,she won second prize in the Croydon Art Society's poster competition ,and shortly afterward was elected the youngest member of the Society. The art critic for the Croydon Advertiser remarked ,\" Her drawings show a remarkable freedom of spirit. She has distinct promise. \" Following her father ’ s death in June 1912 ,the seventeen - year - old Barker submitted art and poetry to My Magazine ,Child ’ s Own ,Leading Strings ,and Raphael Tuck annuals in an effort to support both her mother and sister. Her sister Dorothy taught kindergarten in two private schools before opening a kindergarten at home. She brought in some money for the family's support while supervising the household. = = = Flower Fairies of the Spring ,1923 = = = Fairies became a popular theme in art and literature in the early 20th century following the releases of The Coming of the Fairies by Sir Arthur Conan Doyle ,Peter Pan by J.M. Barrie ,and the fairy - themed work of Australian Ida Rentoul Outhwaite. Queen Mary made such themes even more popular by sending Outhwaite postcards to friends during the 1920s. In 1918 ,Barker produced a postcard series depicting elves and fairies. In 1923 ,Barker sent her flower fairy paintings to various publishers. Blackie paid £ 25 for 24 paintings with accompanying verses ,but it wasn't until publication of Flower Fairies of the Summer in 1925 that Barker received royalties for her work. Mary Violet Clayton Calthrop ,wife of author Dion Clayton Calthrop ,wrote in April 1925 about Barker and Flower Fairies of the Spring: \" She has such exquisite taste ,besides draughtsmanship. \" = = = The Waldrons = = = In 1924 ,the family moved into a four - level ,semi - detached Victorian house at 23 The Waldrons. Barker had a studio built in the garden and her sister conducted a kindergarten in a room at the back of the house. The family lived frugally and attended both St. Edmund's and St. Andrew's in Croydon – \" low \" churches for the less privileged. Barker sometimes incorporated portraits of her fellow parishioners in her religious works. She was described by Canon Ingram Hill as \" one of the pillars \" of St. Andrew's. The children in the kindergarten modelled for the Flower Fairies until the kindergarten closed in 1940. In an interview in 1958 ,Barker said ,\" My sister ran a kindergarten and I used to borrow her students for models. For many years I had an atmosphere of children about me – I never forgot it. \" She also painted the children of relatives as well as Gladys Tidy ,the Barkers' young housekeeper ,who posed for the Primrose Fairy in 1923. The plants were painted from life ,and if a specimen was not readily at hand ,Kew Gardens staff would provide her the specimens needed. Barker designed and built the Flower Fairy costumes ,and based each on the flowers and leaves of the particular plant to be illustrated. The costumes were kept in a trunk in her studio along with wings made of twigs and gauze. Each was broken down after an illustration was completed and the parts recycled for other costumes. She often referred to Dion Clayton Calthrop's English Costume. = = = Middle years = = = In the late 1920s ,Barker began to doubt she was doing enough for the church and considered focusing solely on sacred works. Family and friends recommended she continue secular and sacred works ,which she did. Barker continued to attend evening classes at the Croydon Art School between the 1920s and the 1940s ,eventually receiving a teaching position. She took sketching trips to Amberley and Storrington in Sussex and to Cornwall and the southern coast with family and friends. She visited and stayed with artist Margaret Tarrant in Gomshall ,Surrey and with family in Ugglebarnby ,Near Whitby ,North Yorkshire. In 1940 ,the Barker's live - in maid retired ,and Dorothy Barker closed her school at the back of the house in The Waldrons. She continued to supervise the household ,and to give both her mother and sister the care they needed. Dorothy and her sister collaborated upon only two books: Our Darling's First Book and the Christian - themed ,He Leadeth Me. In 1954 Dorothy Barker died of a heart attack. Barker was unable to pursue her art to any significant extent following her sister's death ,as all the care of her aged mother devolved upon her ,but she did manage to begin planning a stained glass window design in her sister's memory for St. Edmund's ,Pitlake. = = = Later life and death = = = Barker's mother died in 1960 ,and ,in 1961 ,Barker moved from 23 The Waldrons to 6 Duppas Avenue in Croydon. She restored a maisonette in Storrington ,Sussex ,England ,bequeathed by her friend Edith Major ,and named it St. Andrew's. After taking up residence ,her health began to deteriorate. She was in and out of nursing and convalescent homes ,and tended by relatives and friends. Barker died at Worthing Hospital on 16 February 1973 ,aged 77 years. Two funeral services were held – one in Storrington Church and one in Barker's maisonette. Her ashes were scattered in Storrington churchyard. In 1989 ,Frederick Warne ,a division of Penguin Books since 1983 ,acquired the Flower Fairies properties. = = Art = = Barker worked principally in watercolor with pen - and - ink ,but she was equally competent in black - and - white ,in oils ,and in pastels. She carried a sketchbook with her for capturing interesting children. She once indicated ,\" I have always tried to paint instinctively in a way that comes naturally to me ,without any real thought or attention to artistic theories. \" Kate Greenaway was a childhood favorite and an influence on her art. Barker's child subjects wear nostalgic clothing as Greenaway's children do ,though Barker's children are less melancholy and less flat in appearance ,due perhaps to advances in printing technology. Barker studied flowers with an analytical eye and was friend to children's illustrator ,Margaret Tarrant. Along with Greenaway ,illustrator Alice B. Woodward also influenced Barker's work. The Pre - Raphaelites were a strong ,lifelong influence on Barker. She once indicated ,\" I am to some extent influenced by them — not in any technical sense ,but in the choice of subject matter and the feeling and atmosphere they could achieve. \" She admitted a fondness for the early paintings of John Everett Millais and \" the wonderful things \" of Edward Burne - Jones. = = = Depictions of children = = = Barker's sketches ,drawings ,and paintings of children were given to friends or to the parents of the subjects ,donated to charitable institutions and church sponsored events ,or exhibited through various art organizations. She illustrated magazine covers ,dust jackets ,and produced series of postcards for Raphael Tuck and other publishers such as Picturesque Children of the Allies ( 1915 ) ,Seaside Holidays ( 1918 ) ,and Shakespeare's Boy and Girl Characters ( 1917 ,1920 ). Her own Old Rhymes for All Times ( 1928 ) and The Lord of the Rushie River ( 1938 ) ,a tale about a girl who lives among swans on a riverbank ,were critically well received. Set about 1800 ,Groundsel and Necklaces ( 1943 ) tells of a girl named Jenny who rescues her family from poverty through the agency of the fairies. The story features an old Scrooge - like man called Mr. Petercoo and tonally suggests a Dickensian social consciousness. Simon the Swan ,intended as a sequel to Rushie River was outlined in 1943 with Groundsel ,but only developed in 1953. It was published posthumously in 1988 and is critically considered less successful than Groundsel. = = = Christian - themed works = = = Barker was a devout Christian ,and produced religious - themed works throughout her life. She published eight postcards and five guardian angel birthday cards for the Society for Promoting Christian Knowledge in 1916 and in 1923 respectively. Christmas cards were designed for The Girls' Friendly Society over a 20 - year period ,and the first three designs sold out a combined printing of 46 @,@ 500 in 1923. An original design for the society called The Darling of the World Has Come was purchased by Queen Mary for ₤ 5 @.@ 5 @.@ 0 in 1926. The Croydon Art Society hung Barker's booklet cover design for the Society for the Propagation of the Gospel in its November 1919 exhibition. Religious - themed books include The Children's Book of Hymns ( 1929 ) and He Leadeth Me ( 1933 ) ,the latter written in collaboration with her sister. Major religious works include the triptychs in oil ,The Feeding of the Five Thousand ( 1929 ) ,for the chapel in Llandaff House ,a home for destitute women at Penarth ,Wales ,and The Parable of the Great Supper ( 1934 ) for St. George's Chapel ,Waddon. The Feeding has since disappeared ,and only a black - and - white photograph dated 1929 reproduces the work. In 1941 ,she completed oil panels on the subject of the seven sacraments for the baptismal font at St. Andrew's ,South Croydon. She designed baptismal rolls for the wall behind the font in 1948 and 1962. In 1946 ,she completed the 4 x 7 ft. oil painting ,Out of Great Tribulation ,for the Memorial Chapel of Norbury Methodist Church. Following the death of her sister in 1954 ,Barker began designs for a stained glass memorial window depicting Christ preparing to wash the feet of his disciples. Her last religious - themed work ,it was installed in St. Edmund's ,Pitlake ,in 1962. = = Works = = = = = Cards = = = Picturesque Children of the Allies ; J. Salmon ,1916 National Mission ; Society for the Preservation of Christian Knowledge ,1916 Shakespeare's Boy Characters ; C. W. Faulkner ,1917 Shakespeare's Girl Characters ; C. W. Faulkner ,1920 Seaside Holiday ; J. Salmon ,1918 ,1921 Elves and Fairies ; S. Harvey ,1918 Guardian Angel ; Society for the Preservation of Christian Knowledge ,1923 Christmas cards ; Girls' Friendly Society ,1920s ,1930s Christmas cards ( US ) ; Barton - Colton ,1920s ,1930s Beautiful Bible Pictures ; Blackie ,1932 = = = Books = = = Flower Fairies of the Spring ; Blackie ,1923 Spring Songs with Music ; Blackie ,1923 Flower Fairies of the Summer ; Blackie ,1925 Child Thoughts in Picture and Verse ( by M. K. Westcott ) ; Blackie ,1925 Flower Fairies of the Autumn ; Blackie ,1926 Summer Songs with Music ; Blackie ,1926 The Book of the Flower Fairies ; Blackie ,1927 Autumn Songs with Music ; Blackie ,1927 Old Rhymes for All Times ; Blackie ,1928 The Children ’ s Book of Hymns ; Blackie ,1929 ; rep. 1933 Our Darling ’ s First Book ( written in collaboration with Dorothy Barker ) ; Blackie ,1929 The Little Picture Hymn Book ; Blackie ,1933 Rhymes New and Old ; Blackie ,1933 A Flower Fairy Alphabet ; Blackie ,1934 A Little Book of Old Rhymes ; Blackie ,1936 He Leadeth Me ( written in collaboration with Dorothy Barker ) ; Blackie ,1936 A Little Book of Rhymes New and Old ; Blackie ,1937 The Lord of the Rushie River ; Blackie ,1938 Flower Fairies of the Trees ; Blackie ,1940 When Spring Came In at the Window ; Blackie ,1942 A Child ’ s Garden of Verses ( Robert Louis Stevenson ) ; Blackie ,1944 Flower Fairies of the Garden ; Blackie ,1944 Groundsel and Necklaces ; Blackie ,1946 ; reprinted as Fairy Necklaces Flower Fairies of the Wayside ; Blackie ,1948 Flower Fairies of the Flowers and Trees ; Blackie ,1950 Lively Stories ; Macmillan ,1954 The Flower Fairy Picture Book ; Blackie ,1955 Lively Numbers ; Macmillan ,1957 Lively Words ; Macmillan ,1961. The Sand ,the Sea and the Sun ; Gibson ,1970 = = = = Posthumously published = = = = Flower Fairies of the Winter ; Blackie ,1985 Simon the Swan ; Blackie ,1988 Flower Fairies of the Seasons ; Bedrick / Blackie ,1988 A Little Book of Prayers and Hymns ; Frederick Warne ,1994 A Flower Fairies Treasury ; Frederick Warne ,1997 Fairyopolis ; Frederick Warne ,2005 Wild Cherry Makes A Wish ; ( collaboration with Pippa Le Quesne ) Frederick Warne ,2006 How to find Flower Fairies ; Frederick Warne ,2007 Return to Fairyopolis ; Frederick Warne ,2008 = = = Book covers = = = A New Epiphany ; Society for the Preservation of Christian Knowledge ,1919 43 Annuals ; Blackie ,1920s ,1930s = = = Religious works = = = St. Cecily's Garden ; 1920 Cradle roll design ; St. Edmund's ,Pitlake ,1922 Banner design ; St. Mary's ,Sanderstead ,1923 The Feeding of the Five Thousand ; reredos triptych ,chapel at Penarth ,Wales ; 1929 The Parable of the Great Supper ; triptych ,St. George's chapel ,Waddon The Seven Sacraments ; baptismal font panels ,St. Andrew's ,Croydon St. John the Baptist ; central banner panel ,Abesford church ,1943 Lettering ,sword ,and shield ; mount for a list of men and woman serving in the Forces ,St. Andrews ,Croydon ,1943 Baptismal rolls ; St. Andrews ,Croydon ,1948 ,1962 The font in St Andrew's Church ,South Croydon Out of Great Tribulation ; memorial chapel ,Norbury Medthodist church ,1948 I Am Among You As He That Serveth ; stained glass window design ,St. Edmund's ,Pitlake ,1962\n",
      "\n",
      " = Gambia women 's national football team = \n",
      "\n",
      "The Gambia women's national football team represents the Gambia in international football competition. The team ,however ,has not competed in a match recognised by FIFA ,the sport's international governing body ,despite that organised women's football has been played in the country since 1998. The Gambia has two youth teams ,an under - 17 side that has competed in FIFA U - 17 Women's World Cup qualifiers ,and an under - 19 side that withdrew from regional qualifiers for an under - 19 World Cup. The development of a national team faces challenges similar to those across Africa ,although the national football association has four staff members focusing on women's football. = = The team = = In 1985 ,few countries had women's national football teams. While the sport gained popularity worldwide in later decades ,the Gambia's national team only played its first game in 2007. That game was not FIFA - recognised. As of March 2012 ,the team was unranked by FIFA ,and as of the following month the Gambia had not played in a FIFA - sanctioned match. The team has not participated in major regional and international tournaments ,including the Women's World Cup ,the 2010 African Women's Championship or the 2011 All - Africa Games. The country did not have a FIFA - recognised youth national team until 2012 ,when the Gambia under - 17 women's team competed in Confederation of African Football qualifiers for the FIFA U - 17 World Cup ,to be held in Azerbaijan in September 2012. The Gambia had fielded an under - 17 team of 24 players ,narrowed from an initial pool of 49 young women. Two girls from the SOS Children ’ s Village Bakoteh were chosen as a members of the team. The Gambia first played Sierra Leone in a pair of qualifying matches for the tournament. Gambia won the first match 3 - 0 in Banjul ,the Gambia's capital. The return match was delayed in for 24 hours and played in Makeni. The Gambia beat Sierra Leone 4 - 3 to qualify for the final round. The Gambia then beat Tunisia 1 - 0 at home and won 2 - 1 in Tunisia. Adama Tamba and Awa Demba scored the Gambia's goals. Tunisia's only goal was a Gambian own goal. The win qualified Gambia for the 2012 Azerbaijan World Cup. The Gambia also has an under - 19 team that was to play in the African Women's U - 19 Championship in 2002. The Gambia's first match was against Morocco ,but the team withdrew from the competition. = = Background and development = = The development of women's football in Africa faces several challenges ,including limited access to education ,poverty amongst women ,inequalities and human rights abuses targeting women. Funding is another issue impacting the game in Africa ,where most financial assistance comes from FIFA and not national football associations. Another challenge is the retention of football players. Many women footballers leave the continent to seek greater opportunity in Europe or the United States. Gambia's national football association was founded in 1952 ,and became affiliated with FIFA in 1968. Football is the most popular women's sport in the country ,and was first played in an organized system in 1998. A national competition was launched in 2007 ,the same year FIFA started an education course on football for women. Competition was active on both the national and scholastic levels by 2009. There are four staffers dedicated to women's football in the Gambia Football Association ,and representation of women on the board is required by the association's charter.\n",
      "\n",
      " = Plain maskray = \n",
      "\n",
      "The plain maskray or brown stingray ( Neotrygon annotata ) is a species of stingray in the family Dasyatidae. It is found in shallow ,soft - bottomed habitats off northern Australia. Reaching 24 cm ( 9 @.@ 4 in ) in width ,this species has a diamond - shaped ,grayish green pectoral fin disc. Its short ,whip - like tail has alternating black and white bands and fin folds above and below. There are short rows of thorns on the back and the base of the tail ,but otherwise the skin is smooth. While this species possesses the dark mask - like pattern across its eyes common to its genus ,it is not ornately patterned like other maskrays. Benthic in nature ,the plain maskray feeds mainly on caridean shrimp and polychaete worms ,and to a lesser extent on small bony fishes. It is viviparous ,with females producing litters of one or two young that are nourished during gestation via histotroph ( \" uterine milk \" ). This species lacks economic value but is caught incidentally in bottom trawls ,which it is thought to be less able to withstand than other maskrays due to its gracile build. As it also has a limited distribution and low fecundity ,the International Union for Conservation of Nature ( IUCN ) has listed it as Near Threatened. = = Taxonomy and phylogeny = = The first scientific description of the plain maskray was authored by Commonwealth Scientific and Industrial Research Organisation ( CSIRO ) researcher Peter Last in a 1987 issue of Memoirs of the National Museum of Victoria. The specific name annotatus comes from the Latin an ( \" not \" ) and notatus ( \" marked \" ) ,and refers to the ray's coloration. The holotype is a male 21 @.@ 2 cm ( 8 @.@ 3 in ) across ,caught off Western Australia ; several paratypes were also designated. Last tentatively placed the species in the genus Dasyatis ,noting that it belonged to the \" maskray \" species group that also included the bluespotted stingray ( then Dasyatis kuhlii ). In 2008 ,Last and William White elevated the kuhlii group to the rank of full genus as Neotrygon ,on the basis of morphological and molecular phylogenetic evidence. In a 2012 phylogenetic analysis based on mitochondrial and nuclear DNA ,the plain maskray and the Ningaloo maskray ( N. ningalooensis ) were found to be the most basal members of Neotrygon. The divergence of the N. annotata lineage was estimated to have occurred ~ 54 Ma. Furthermore ,the individuals sequenced in the study sorted into two genetically distinct clades ,suggesting that N. annotata is a cryptic species complex. The two putative species were estimated to have diverged ~ 4 @.@ 9 Ma ; the precipitating event was likely the splitting of the ancestral population by coastline changes. = = Description = = The pectoral fin disc of the plain maskray is thin and diamond - shaped with narrowly rounded outer corners ,measuring 1 @.@ 1 – 1 @.@ 3 times longer than wide. The leading margins of the disc are gently concave and converge at a broad angle to the pointed tip of the snout. The small eyes are placed close together ,and behind them are the spiracles. The nostrils are elongated and have a skirt - shaped flap of skin between them. The small mouth bears prominent furrows at the corners and contains two slender papillae on the floor. Small papillae are also found around the outside of the mouth. There are five pairs of gill slits. The pelvic fins are fairly large and pointed. The tail is short ,barely exceeding the length of the disc when intact ,and has a broad and flattened base leading to usually two stinging spines. After the stings ,the tail becomes slender and bears a long ventral fin fold and a much shorter ,lower dorsal fin fold. Most of the body lacks dermal denticles ; a midline row of 4 – 13 small ,closely spaced thorns is present behind the spiracles ,and another row of 0 – 4 thorns before the stings. The dorsal coloration is grayish green ,becoming pinkish towards the disc margins ; there is a dark mask - like shape around the eyes and a pair of small dark blotches behind the spiracles. The tail behind the stings has alternating black and white bands of variable width ,ending with black at the tip. The underside is plain white and the ventral fin fold is light grayish in color. This species grows to 24 cm ( 9 @.@ 4 in ) across and 45 cm ( 18 in ) long. = = Distribution and habitat = = The plain maskray inhabits the continental shelf of northern Australia from the Wellesley Islands in Queensland to the Bonaparte Archipelago in Western Australia ,including the Gulf of Carpentaria and the Timor and Arafura Seas. There are unsubstantiated reports that its range extends to southern Papua New Guinea. It is the least common of the several maskray species native to the region. This species is a bottom - dweller that prefers habitats with fine sediment. It has been recorded from between 12 and 62 m ( 39 and 203 ft ) deep ,and tends to be found farther away from shore than other maskrays in its range. = = Biology and ecology = = The plain maskray generally hunts at the surface of the bottom substrate ,rather than digging for prey. Its diet consists predominantly of caridean shrimp and polychaete worms. Small bony fishes are also eaten ,along with the occasional penaeid prawn or amphipod. Larger rays consume a greater variety of prey and relatively more polychaete worms when compared to smaller rays. This species is parasitized by the tapeworm Acanthobothrium jonesi. Like other stingrays ,the plain maskray is viviparous with the developing embryos sustained to term by histotroph ( \" uterine milk \" ) produced by the mother. Mature females have a single functional ovary and uterus ,on the left. Litter size is one or two ; the newborns measure 12 – 14 cm ( 4 @.@ 7 – 5 @.@ 5 in ) across. Males and females reach sexual maturity at disc widths of 20 – 21 cm ( 7 @.@ 9 – 8 @.@ 3 in ) and 18 – 19 cm ( 7 @.@ 1 – 7 @.@ 5 in ) respectively. The maximum lifespan is estimated to be 9 years for males and 13 years for females. = = Human interactions = = The main conservation threat to the plain maskray is incidental capture by commercial bottom trawl fisheries. In the present day ,this is mostly caused by Australia's Northern Prawn Fishery ,which operates throughout its range. Although this species is discarded when caught ,it is more delicate - bodied than other maskrays and is thus unlikely to survive encounters with trawling gear. Historically ,this species may also have been negatively affected by Japanese ,Chinese ,and Taiwanese trawlers that fished intensively off northern Australia from 1959 to 1990. These factors ,coupled with the plain maskray's limited distribution and low reproductive rate ,have resulted in its being assessed as Near Threatened by the International Union for Conservation of Nature ( IUCN ).\n",
      "\n",
      " = 2011 – 12 Columbus Blue Jackets season = \n",
      "\n",
      "The 2011 – 12 Columbus Blue Jackets season was the team's 12th season in the National Hockey League ( NHL ). The Blue Jackets' record of 29 – 46 – 7 [ note 1 ] was the worst record in the NHL for 2011 – 12 and the first time in franchise history they finished in last place. It also marked the third straight year that they missed the playoffs. Consequently ,they had the best chance to receive the first overall selection in the 2012 NHL Entry Draft lottery ,but lost out to the Edmonton Oilers and received the second pick instead. The Blue Jackets began the year with the worst start in franchise history and the worst by any team in an NHL season in 19 years. After an 11 – 25 – 5 start ,Head Coach Scott Arniel was fired and replaced by Assistant Coach Todd Richards. The poor season prompted several personnel changes including the trade of All - Star forward Jeff Carter ,who was acquired with much fanfare during the off - season. With the prospect of another rebuild looming the Blue Jackets' captain and best player ,Rick Nash ,requested to be traded ,though he would remain with the team for the entire season. The team was involved in a controversial loss to the Los Angeles Kings ,when the Staples Center clock appeared to freeze at 1 @.@ 8 seconds allowing the Kings time to score the tying goal ,before winning in overtime. During the season Columbus managed only two winning streaks of three or more games. One of which came towards the end of the year helping the Blue Jackets finish with 65 points ,the third worst point total in franchise history. = = Off - season = = In the off - season the Blue Jackets' approach to building their team changed ,moving from a team of young developing players into one with established players. The first deal General Manager Scott Howson made was the acquisition of All - Star forward Jeff Carter on June 23 ,2011. The deal sent Jakub Voracek ,Columbus' first - round draft choice ,the eighth overall ,and their third - round pick in the 2011 Draft to the Philadelphia Flyers in exchange for Carter. The trade received a positive response in Columbus from fans and management who felt they finally had a number one center to play alongside of their best player ,Rick Nash. Next ,they traded for the negotiating rights of soon to be free agent James Wisniewski. Wisniewski scored a career high 51 points during the 2010 – 11 season ,splitting time between the New York Islanders and Montreal Canadiens. The point total was fifth - highest in the league for defenseman scoring ,tying Tobias Enstrom. The Blue Jackets came to terms with Wisniewski ,just an hour prior to the start of free agency ,signing him to a six - year ,$ 33 million deal. Columbus also traded former first round draft pick Nikita Filatov to the Ottawa Senators for a third - round pick in the 2011 Draft. Filatov had failed to live up to expectations in Columbus ,playing in only 44 games over three seasons scoring six goals. Prior to the start of the season ,the Blue Jackets were questioned for not signing a veteran back - up to starting goaltender Steve Mason ,as the former Calder Memorial Trophy winner had struggled in consecutive seasons. The Blue Jackets signed Mark Dekanich as the back - up who had only 50 minutes of NHL experience prior to the start of the season. Columbus did sign a veteran Curtis Sanford to be their third string goaltender and to start for their American Hockey League ( AHL ) affiliate ,the Springfield Falcons. Sanford had not played in the NHL since 2009. During training camp ,Dekanich suffered a high ankle sprain that was expected to keep him out of the line - up for a month. Additionally ,Sanford suffered a groin injury ,leaving Allen York as the back - up. York had only played four professional games ,all in the AHL ,entering the season. = = Regular season = = = = = October – December = = = After the first five games ,all losses ,Jeff Carter suffered a broken foot that kept him out of the line - up for 10 games. While Carter was injured ,the Blue Jackets continued to lose games. In the eighth game of the year ,they had a chance to end the losing streak against the Ottawa Senators. Columbus held a 3 – 2 lead with under a minute to play. Jason Spezza tied the game on a late power play ,and with just 4 @.@ 7 seconds remaining ,Milan Michalek notched the winning goal for the Senators. The loss helped set a franchise record for futility with a 0 – 7 – 1 record to start a season. [ note 1 ] The losing streak came to an end three days later with a win over the Detroit Red Wings. During the game ,several milestones were reached. James Wisniewski made his Columbus debut ,Ryan Johansen and John Moore scored their first career NHL goals and Grant Clitsome had a career - high three assists. Columbus was unable to create any momentum from the win ,however ,and continued to struggle ,culminating in a 2 – 12 – 1 record ,which was the worst start to an NHL season for any team in 19 years. With the team struggling ,management attempted to \" shake things up \" by making some roster moves. The first move was the acquisition of center Mark Letestu from the Pittsburgh Penguins. Next ,they traded defenseman Kris Russell to the St. Louis Blues for Nikita Nikitin. As the clubs slow start continued ,there were rumors that Head Coach Scott Arniel would be fired and replaced with Ken Hitchcock. Hitchcock had previously coached the Blue Jackets to their only playoff appearance in club history and was still under contract with the franchise through to the end of the season. Before any of these rumors came to fruition ,the St. Louis Blues asked Columbus for permission to hire Hitchcock ,which the Blue Jackets allowed. Hitchcock began his Blues coaching career with a 6 – 1 – 2 record in his first nine games ,while Columbus amassed a 6 – 13 – 3 record to start the season. During the same time frame as the Hitchcock rumors ,goaltender Curtis Sanford returned from his groin injury on November 13. He made his first start of the season against the Boston Bruins ,losing 2 – 1 in a shootout. Sanford continued his strong play ,posting a 3 – 1 – 2 record ,1 @.@ 38 goals against average and.947 save percentage over his next six games. Sanford started 12 consecutive games before Steve Mason made his next start. The number of starts might not have been as numerous ,but prior to the November 23 game ,Mason was hit in the head by a shot from Rick Nash during pre - game warm - ups and suffered a concussion. Mason returned from his concussion after two games ,making a start against the Vancouver Canucks. Mason allowed only one goal in the game despite suffering from cramping in the third period ,temporarily being replaced by Sanford for just over three minutes. Columbus won the game 2 – 1 in a shootout ,breaking a nine - game losing streak to the Canucks. After the game ,Arniel stated that Sanford was still seen as the team's number one goaltender. However ,Mason started four of the next six games with the Blue Jackets going 0 – 5 – 1 during that stretch. = = = January – February = = = With the losing continuing ,more rumors began to surface. Unlike before ,the rumors were about player moves rather than coaching changes. The majority of rumors were that the Blue Jackets would trade Rick Nash. While Howson stated that he had never brought up trading Nash in discussions ,other teams had inquired about his availability. Nash stated that if Columbus felt it would make the franchise better than he would be willing to waive his no - trade clause. Howson publicly stated that he had no intention of trading Nash. More rumors came to light when reports attributed to Réseau des sports stated that Carter was unhappy in Columbus and demanded a trade. Howson ,Carter and his agent all denied that a trade request was ever made ,and they were unsure where the reports were coming from. With the trade deadline approaching ,speculation picked up on the Blue Jackets trading Carter. Reports were that Columbus was trying to trade Carter and that he was \" 100 percent available. \" At the halfway point of the season ,with the Blue Jackets barely into double digit wins with an 11 – 25 – 5 record ,worst in the league ,and sitting 20 points out of playoff position ,Columbus fired Arniel. He was replaced by Assistant Coach Todd Richards on an interim basis. Richards had previously coached the Minnesota Wild. He recorded his first coaching victory for the Blue Jackets in his second game ,a 4 – 3 win over the Phoenix Coyotes. The change in coaching did not change the fortunes of the team ,as they reached the All - Star break with a 13 – 30 – 6 record. At the break ,Blue Jackets' owner John P. McConnell sent out a letter to fans stating his understanding of their frustration. He added that action would be taken around the trade deadline ,the Entry Draft and free agency to take the team in a new direction. When speaking of the season ,McConnell stated \" disappointing is not a strong enough word \" and that he was committed to giving fans a team of which they can be proud of. He also thanked them for their dedication and passion ,while reiterating that the team goal was to \" win consistently and compete for the Stanley Cup. \" Days later ,a 250 - person protest occurred outside of Nationwide Arena. Fans were upset with the Blue Jackets' management and were calling for changes at the top. The same day the fans protested ,it was announced that the franchise would host the 2013 All - Star Game. Columbus was without a representative for the 2012 All - star Game ,but Ryan Johansen represented the club as a rookie participant in the Super Skills Competition. In the competition ,Johansen participated in the Allstate Insurance NHL Breakaway Challenge ,a shootout themed event judged by the fans. He received just 1 % of the vote and finished last. Following the break ,the Blue Jackets were on the road playing the Los Angeles Kings ,and with the score tied late in the game ,Kings' defenseman Drew Doughty scored with just 0 @.@ 4 seconds remaining to win the game. Upon review of the goal it ,was determined that the clock at Staples Center froze at 1 @.@ 8 seconds for over a full second ,which would have resulted in time expiring prior to the goal being scored. Kings' General Manager Dean Lombardi stated that the clock was correct and no extra time had been added due to the way the clock self - corrects at various times. Howson stated on the team's blog that \" It is an amazing coincidence that with the Kings on a power play at Staples Center and with a mad scramble around our net in the dying seconds of the third period of a 2 – 2 hockey game that the clock stopped for at least one full second ,\" adding that ,\" Either there was a deliberate stopping of the clock or the clock malfunctioned. \" NHL Senior Vice President of Hockey Operations Colin Campbell stated that the Blue Jackets were wronged ,but that the outcome of the game could not be changed ,and that the delay was not noticed by the off - ice officials or the situation room in Toronto. To determine the true cause of the clock pause ,the NHL launched an investigation ,talking with the clock's manufacturer and interviewing Staples Center staff. Two weeks prior to the NHL trade deadline ,Columbus announced that unlike earlier in the season ,they would listen to trade proposals involving Rick Nash ,though they were not actively shopping him. Howson stated that the team was open to all options for improving the team ,including trading Nash. Speculation was that in return for Nash the Blue Jackets would ask for a \" combination of young ,proven players ,high - end prospects and draft picks. \" Leading up to the trade deadline ,the Blue Jackets dealt Antoine Vermette to the Phoenix Coyotes for two draft picks and goaltender Curtis McElhinney. Despite being injured at the time ,the acquisition of McElhinney was believed to give Columbus the flexibility to trade Curtis Sanford. The following day ,on February 23 ,Columbus traded Jeff Carter to the Kings. In the deal ,Columbus acquired defenseman Jack Johnson and a first - round draft pick ; the team was given the choice of taking the pick in either 2012 or 2013. At the deadline ,Columbus was unable to come to terms on a deal involving Nash ,but they did make one more move ; they sent center Samuel Pahlsson to the Vancouver Canucks in exchange for two fourth - round draft picks and minor league defenseman Taylor Ellington. Following the trade deadline ,Howson announced that the team had attempted to trade Nash at the player's request. Nash stated that he had requested the trade after being informed that the franchise was going into another rebuilding phase. He further noted that he felt that he \" could be a huge part of that towards bringing assets in ,\" and in his view \" it was the best thing for the team ,the organization ,and personally for [ his ] career. \" After the personnel changes ,the Blue Jackets closed out the month with a three - game losing streak. = = = March – April = = = Columbus started March with a 2 – 0 shutout against the Colorado Avalanche. They proceeded to win their next game against the Phoenix Coyotes 5 – 2 ,which marked the first time that the Blue Jackets posted back - to - back regulation victories during the season. Columbus again defeated the Coyotes three days later to earn their first three - game win streak of the season. They extended the streak to four with a win over the Los Angeles Kings before it came to an end with a 4 – 1 loss to the St. Louis Blues. It was the only four - game win streak of the season for the Blue Jackets. They immediately matched their four - game win streak with a four - game losing streak and with ten games remaining ,the Blue Jackets were the first team eliminated from playoff contention. Shortly after being eliminated ,they were defeated by the Edmonton Oilers 6 – 3 ; the loss clinched last place in the NHL for Columbus. It was the first time in franchise history the Blue Jackets finished in 30th place. Three days later ,on March 28 ,goaltender Steve Mason was injured in the morning skate when a shot from Colton Gillies hit him in the mask. With Sanford again injured ,York made an emergency start. Playing against the Detroit Red Wings ,York made 29 saves ,including 17 in the third period ,helping Columbus to a 4 – 2 victory and giving York his first career NHL win. York remained the starter and led the Blue Jackets to a second three - game winning streak. In his fourth start ,Columbus was shutout by the Coyotes despite a franchise - record 54 shots on goal ,losing 2 – 0. The 54 saves by Phoenix goaltender Mike Smith set an NHL record for a regulation shutout. Mason returned to the starter's role for the final two games ,winning both. The two victories gave Columbus 65 points for the year ,their third - lowest total in franchise history. The Blue Jackets struggled in shorthanded situations ,allowing the most power - play goals in the League ,with 64 ,and having the lowest penalty - kill percentage ,at 76 @.@ 64 % = = Post - season = = Finishing with the worst record in the NHL ,Columbus had the best chance of receiving the first overall pick in the 2012 draft. With the NHL's weighted draft lottery the Blue Jackets had a 48 @.@ 2 % chance of drafting first overall. However ,the lottery was won by the Edmonton Oilers ,who proceeded to leapfrog Columbus and secure the number one draft pick for a third consecutive year. It was the fifth time that the Blue Jackets were dropped one draft position in the franchise's 12 lottery participations. A month later ,on May 14 ,the Blue Jackets announced that Richards would remain as head coach and signed him to a two - year contract. During the press conference ,Howson noted ,\" Our team continuously improved under Todd and he has earned the opportunity to build upon the work he started. \" Columbus posted an 18 – 21 – 2 record under Richards ,including winning seven of their final 11 games. = = Standings = = Since being founded as an expansion team ,the Blue Jackets have played in the Central Division of the Western Conference. Division rivals Chicago Blackhawks ,Detroit Red Wings ,Nashville Predators and St. Louis Blues ,all made the playoff during the 2011 – 12 season ,which helped Columbus finish 36 points behind fourth place Chicago and 44 points out of first. Divisions: CE – Central ,NW – Northwest ,PA – Pacific bold - qualified for playoffs ,y – Won division ,p – Won Presidents' Trophy ( best record in NHL ) = = Schedule and results = = = = = Pre - season = = = = = = Regular season = = = Green background indicates win ( 2 points ). Red background indicates regulation loss ( 0 points ). Silver background indicates overtime / shootout loss ( 1 point ). = = Player statistics = = In ice hockey ,a combination of a player's goals and assists are collectively called points. Penalty minutes are the total number of minutes assigned to a player for infractions assessed during the season.Plus - minus is a statistic that tracks when a player was on the ice while goals were scored ,both for and against their team ,though some in game situations will not effect the statistic. Below is a listing of all player statistics for the Blue Jackets during the season. = = = Skaters = = = Note: Pos\n",
      "\n",
      " = Position ; GP = \n",
      "\n",
      "Games played in ; G\n",
      "\n",
      " = Goals ; A = \n",
      "\n",
      "Assists ; Pts\n",
      "\n",
      " = Points ; PIM = \n",
      "\n",
      "Penalty minutes ; + / - = Plus / minus = = = Goaltenders = = = Note: GP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc in wikitext_docs[:10]:\n",
    "    print(doc.metadata[\"title\"])\n",
    "    print(doc.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowest_common_ancestor(token1, token2):\n",
    "    path1 = list(token1.ancestors)\n",
    "    path2 = list(token2.ancestors)\n",
    "    \n",
    "    if token1 in path2:\n",
    "        return token1\n",
    "    if token2 in path1:\n",
    "        return token2\n",
    "\n",
    "    for ancestor in path1:\n",
    "        if ancestor in path2:\n",
    "            return ancestor\n",
    "\n",
    "    return None\n",
    "\n",
    "def find_root_verb(subject, object, sent):\n",
    "    subject_token = subject.root\n",
    "    object_token = object.root\n",
    "    \n",
    "    if subject_token.i > object_token.i:\n",
    "        subject_token, object_token = object_token, subject_token\n",
    "\n",
    "    lca = lowest_common_ancestor(subject_token, object_token)\n",
    "    \n",
    "    if lca.pos_ == \"VERB\":\n",
    "        return lca\n",
    "    \n",
    "    while lca.head != lca:\n",
    "        if lca.pos_ == \"VERB\":\n",
    "            return lca\n",
    "        lca = lca.head\n",
    "    \n",
    "    return None\n",
    "\n",
    "def extract_triplets(text):\n",
    "    doc = nlp(text)\n",
    "    triplets = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        entity_tokens = [ent for ent in sent.ents]\n",
    "        \n",
    "        # Extract subject-object pairs\n",
    "        for subject, object in combinations(entity_tokens, 2):\n",
    "            # Find the root verb between subject and object\n",
    "            root_verb = find_root_verb(subject, object, sent)\n",
    "            if root_verb:\n",
    "                triplets.append((subject.text, root_verb.lemma_, object.text))\n",
    "\n",
    "        # Extract noun-chunks based triplets\n",
    "        noun_chunks = list(sent.noun_chunks)\n",
    "        for chunk in noun_chunks:\n",
    "            if chunk.root.dep_ in [\"nsubj\", \"nsubjpass\"]:\n",
    "                verb = chunk.root.head\n",
    "                for child in verb.children:\n",
    "                    if child.dep_ in [\"dobj\", \"attr\", \"prep\"]:\n",
    "                        triplets.append((chunk.text, verb.lemma_, child.text))\n",
    "\n",
    "    return triplets\n",
    "\n",
    "def build_knowledge_graph(documents):\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    for doc in documents:\n",
    "        triplets = extract_triplets(doc.text)\n",
    "        for subject, predicate, object in triplets:\n",
    "            G.add_edge(subject, object, relation=predicate)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_graph = build_knowledge_graph(wikitext_docs)\n",
    "\n",
    "print(f\"Knowledge Graph built with {knowledge_graph.number_of_nodes()} nodes and {knowledge_graph.number_of_edges()} edges\")\n",
    "\n",
    "# Display some triplets\n",
    "print(\"\\nSample triplets:\")\n",
    "for edge in list(knowledge_graph.edges(data=True))[:10]:\n",
    "    print(f\"{edge[0]} -- {edge[2]['relation']} --> {edge[1]}\")\n",
    "\n",
    "# Basic analysis\n",
    "print(f\"\\nMost common relations:\")\n",
    "relation_counts = Counter([edge[2]['relation'] for edge in knowledge_graph.edges(data=True)])\n",
    "for relation, count in relation_counts.most_common(5):\n",
    "    print(f\"{relation}: {count}\")\n",
    "\n",
    "print(f\"\\nMost connected entities:\")\n",
    "degree_centrality = nx.degree_centrality(knowledge_graph)\n",
    "for entity, centrality in sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"{entity}: {centrality:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 10/10 [00:00<00:00, 154.17it/s]\n",
      "Processing nodes:   0%|          | 0/66 [00:00<?, ?it/s]\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      44.36 ms /   512 runs   (    0.09 ms per token, 11542.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9485.39 ms /   114 tokens (   83.21 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:        eval time =   29853.05 ms /   511 runs   (   58.42 ms per token,    17.12 tokens per second)\n",
      "llama_print_timings:       total time =   40134.50 ms /   625 tokens\n",
      "Generating embeddings: 100%|██████████| 18/18 [00:00<00:00, 44.02it/s]\n",
      "Processing nodes:   2%|▏         | 1/66 [00:40<43:56, 40.56s/it]Llama.generate: 110 prefix-match hit, remaining 465 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      36.53 ms /   408 runs   (    0.09 ms per token, 11170.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12276.08 ms /   465 tokens (   26.40 ms per token,    37.88 tokens per second)\n",
      "llama_print_timings:        eval time =   20254.71 ms /   407 runs   (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_print_timings:       total time =   33119.83 ms /   872 tokens\n",
      "Generating embeddings: 100%|██████████| 18/18 [00:00<00:00, 407.93it/s]\n",
      "Processing nodes:   3%|▎         | 2/66 [01:13<38:37, 36.21s/it]Llama.generate: 119 prefix-match hit, remaining 455 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      46.61 ms /   512 runs   (    0.09 ms per token, 10984.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12637.17 ms /   455 tokens (   27.77 ms per token,    36.00 tokens per second)\n",
      "llama_print_timings:        eval time =   27252.85 ms /   511 runs   (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:       total time =   40689.34 ms /   966 tokens\n",
      "Generating embeddings: 100%|██████████| 32/32 [00:00<00:00, 393.37it/s]\n",
      "Processing nodes:   5%|▍         | 3/66 [01:54<40:12, 38.30s/it]Llama.generate: 119 prefix-match hit, remaining 478 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      32.02 ms /   359 runs   (    0.09 ms per token, 11212.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12104.38 ms /   478 tokens (   25.32 ms per token,    39.49 tokens per second)\n",
      "llama_print_timings:        eval time =   20198.70 ms /   358 runs   (   56.42 ms per token,    17.72 tokens per second)\n",
      "llama_print_timings:       total time =   32807.62 ms /   836 tokens\n",
      "Generating embeddings: 100%|██████████| 24/24 [00:00<00:00, 364.61it/s]\n",
      "Processing nodes:   6%|▌         | 4/66 [02:27<37:21, 36.16s/it]Llama.generate: 119 prefix-match hit, remaining 468 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      23.01 ms /   294 runs   (    0.08 ms per token, 12776.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12083.78 ms /   468 tokens (   25.82 ms per token,    38.73 tokens per second)\n",
      "llama_print_timings:        eval time =   15029.85 ms /   293 runs   (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:       total time =   27448.46 ms /   761 tokens\n",
      "Generating embeddings: 100%|██████████| 20/20 [00:00<00:00, 477.42it/s]\n",
      "Processing nodes:   8%|▊         | 5/66 [02:54<33:35, 33.04s/it]Llama.generate: 119 prefix-match hit, remaining 474 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      43.74 ms /   512 runs   (    0.09 ms per token, 11706.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12018.98 ms /   474 tokens (   25.36 ms per token,    39.44 tokens per second)\n",
      "llama_print_timings:        eval time =   27921.85 ms /   511 runs   (   54.64 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:       total time =   40724.33 ms /   985 tokens\n",
      "Generating embeddings: 100%|██████████| 26/26 [00:00<00:00, 405.46it/s]\n",
      "Processing nodes:   9%|▉         | 6/66 [03:35<35:40, 35.68s/it]Llama.generate: 119 prefix-match hit, remaining 459 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      45.38 ms /   512 runs   (    0.09 ms per token, 11283.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11858.04 ms /   459 tokens (   25.83 ms per token,    38.71 tokens per second)\n",
      "llama_print_timings:        eval time =   26218.89 ms /   511 runs   (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_print_timings:       total time =   38861.57 ms /   970 tokens\n",
      "Generating embeddings: 100%|██████████| 18/18 [00:00<00:00, 419.00it/s]\n",
      "Processing nodes:  11%|█         | 7/66 [04:14<36:07, 36.74s/it]Llama.generate: 119 prefix-match hit, remaining 479 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      30.74 ms /   350 runs   (    0.09 ms per token, 11385.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12042.36 ms /   479 tokens (   25.14 ms per token,    39.78 tokens per second)\n",
      "llama_print_timings:        eval time =   24746.62 ms /   349 runs   (   70.91 ms per token,    14.10 tokens per second)\n",
      "llama_print_timings:       total time =   37271.95 ms /   828 tokens\n",
      "Generating embeddings: 100%|██████████| 20/20 [00:00<00:00, 401.94it/s]\n",
      "Processing nodes:  12%|█▏        | 8/66 [04:51<35:41, 36.93s/it]Llama.generate: 119 prefix-match hit, remaining 460 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      45.13 ms /   512 runs   (    0.09 ms per token, 11346.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12145.51 ms /   460 tokens (   26.40 ms per token,    37.87 tokens per second)\n",
      "llama_print_timings:        eval time =   25632.73 ms /   511 runs   (   50.16 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:       total time =   38571.33 ms /   971 tokens\n",
      "Generating embeddings: 100%|██████████| 16/16 [00:00<00:00, 390.55it/s]\n",
      "Processing nodes:  14%|█▎        | 9/66 [05:30<35:35, 37.46s/it]Llama.generate: 119 prefix-match hit, remaining 483 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      25.15 ms /   301 runs   (    0.08 ms per token, 11966.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12954.48 ms /   483 tokens (   26.82 ms per token,    37.28 tokens per second)\n",
      "llama_print_timings:        eval time =   17201.35 ms /   300 runs   (   57.34 ms per token,    17.44 tokens per second)\n",
      "llama_print_timings:       total time =   30542.41 ms /   783 tokens\n",
      "Generating embeddings: 100%|██████████| 21/21 [00:00<00:00, 345.48it/s]\n",
      "Processing nodes:  15%|█▌        | 10/66 [06:01<32:59, 35.35s/it]Llama.generate: 119 prefix-match hit, remaining 459 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      46.65 ms /   512 runs   (    0.09 ms per token, 10974.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12446.82 ms /   459 tokens (   27.12 ms per token,    36.88 tokens per second)\n",
      "llama_print_timings:        eval time =   27667.90 ms /   511 runs   (   54.14 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:       total time =   40894.10 ms /   970 tokens\n",
      "Generating embeddings: 100%|██████████| 8/8 [00:00<00:00, 278.19it/s]\n",
      "Processing nodes:  17%|█▋        | 11/66 [06:42<33:58, 37.06s/it]Llama.generate: 119 prefix-match hit, remaining 470 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      31.16 ms /   384 runs   (    0.08 ms per token, 12324.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12215.25 ms /   470 tokens (   25.99 ms per token,    38.48 tokens per second)\n",
      "llama_print_timings:        eval time =   21585.15 ms /   383 runs   (   56.36 ms per token,    17.74 tokens per second)\n",
      "llama_print_timings:       total time =   34296.11 ms /   853 tokens\n",
      "Generating embeddings: 100%|██████████| 21/21 [00:00<00:00, 335.90it/s]\n",
      "Processing nodes:  18%|█▊        | 12/66 [07:16<32:37, 36.24s/it]Llama.generate: 119 prefix-match hit, remaining 464 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      47.49 ms /   512 runs   (    0.09 ms per token, 10781.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11621.22 ms /   464 tokens (   25.05 ms per token,    39.93 tokens per second)\n",
      "llama_print_timings:        eval time =   33221.90 ms /   511 runs   (   65.01 ms per token,    15.38 tokens per second)\n",
      "llama_print_timings:       total time =   45587.83 ms /   975 tokens\n",
      "Generating embeddings: 100%|██████████| 12/12 [00:00<00:00, 352.71it/s]\n",
      "Processing nodes:  20%|█▉        | 13/66 [08:02<34:31, 39.09s/it]Llama.generate: 119 prefix-match hit, remaining 457 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      51.65 ms /   512 runs   (    0.10 ms per token,  9913.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11716.91 ms /   457 tokens (   25.64 ms per token,    39.00 tokens per second)\n",
      "llama_print_timings:        eval time =   35089.45 ms /   511 runs   (   68.67 ms per token,    14.56 tokens per second)\n",
      "llama_print_timings:       total time =   47639.17 ms /   968 tokens\n",
      "Generating embeddings: 100%|██████████| 13/13 [00:00<00:00, 353.31it/s]\n",
      "Processing nodes:  21%|██        | 14/66 [08:49<36:07, 41.69s/it]Llama.generate: 119 prefix-match hit, remaining 433 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      32.34 ms /   441 runs   (    0.07 ms per token, 13634.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11538.60 ms /   433 tokens (   26.65 ms per token,    37.53 tokens per second)\n",
      "llama_print_timings:        eval time =   30074.44 ms /   440 runs   (   68.35 ms per token,    14.63 tokens per second)\n",
      "llama_print_timings:       total time =   42115.44 ms /   873 tokens\n",
      "Generating embeddings: 100%|██████████| 28/28 [00:00<00:00, 427.25it/s]\n",
      "Processing nodes:  23%|██▎       | 15/66 [09:32<35:33, 41.84s/it]Llama.generate: 119 prefix-match hit, remaining 334 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      41.06 ms /   512 runs   (    0.08 ms per token, 12469.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10430.57 ms /   334 tokens (   31.23 ms per token,    32.02 tokens per second)\n",
      "llama_print_timings:        eval time =   33608.28 ms /   511 runs   (   65.77 ms per token,    15.20 tokens per second)\n",
      "llama_print_timings:       total time =   44709.91 ms /   845 tokens\n",
      "Generating embeddings: 100%|██████████| 37/37 [00:00<00:00, 459.76it/s]\n",
      "Processing nodes:  24%|██▍       | 16/66 [10:16<35:36, 42.73s/it]Llama.generate: 113 prefix-match hit, remaining 466 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      47.09 ms /   512 runs   (    0.09 ms per token, 10873.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11333.14 ms /   466 tokens (   24.32 ms per token,    41.12 tokens per second)\n",
      "llama_print_timings:        eval time =   32916.06 ms /   511 runs   (   64.41 ms per token,    15.52 tokens per second)\n",
      "llama_print_timings:       total time =   44956.59 ms /   977 tokens\n",
      "Generating embeddings: 100%|██████████| 24/24 [00:00<00:00, 325.11it/s]\n",
      "Processing nodes:  26%|██▌       | 17/66 [11:01<35:27, 43.43s/it]Llama.generate: 121 prefix-match hit, remaining 474 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      44.76 ms /   476 runs   (    0.09 ms per token, 10634.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11416.00 ms /   474 tokens (   24.08 ms per token,    41.52 tokens per second)\n",
      "llama_print_timings:        eval time =   30440.46 ms /   475 runs   (   64.09 ms per token,    15.60 tokens per second)\n",
      "llama_print_timings:       total time =   42481.27 ms /   949 tokens\n",
      "Generating embeddings: 100%|██████████| 21/21 [00:00<00:00, 305.04it/s]\n",
      "Processing nodes:  27%|██▋       | 18/66 [11:44<34:32, 43.17s/it]Llama.generate: 121 prefix-match hit, remaining 470 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      47.07 ms /   512 runs   (    0.09 ms per token, 10877.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11288.25 ms /   470 tokens (   24.02 ms per token,    41.64 tokens per second)\n",
      "llama_print_timings:        eval time =   34393.60 ms /   511 runs   (   67.31 ms per token,    14.86 tokens per second)\n",
      "llama_print_timings:       total time =   46342.89 ms /   981 tokens\n",
      "Generating embeddings: 100%|██████████| 53/53 [00:00<00:00, 505.18it/s]\n",
      "Processing nodes:  29%|██▉       | 19/66 [12:30<34:35, 44.16s/it]Llama.generate: 121 prefix-match hit, remaining 471 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      23.36 ms /   265 runs   (    0.09 ms per token, 11346.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11390.95 ms /   471 tokens (   24.18 ms per token,    41.35 tokens per second)\n",
      "llama_print_timings:        eval time =   17447.83 ms /   264 runs   (   66.09 ms per token,    15.13 tokens per second)\n",
      "llama_print_timings:       total time =   29146.75 ms /   735 tokens\n",
      "Generating embeddings: 100%|██████████| 17/17 [00:00<00:00, 412.19it/s]\n",
      "Processing nodes:  30%|███       | 20/66 [13:00<30:24, 39.67s/it]Llama.generate: 121 prefix-match hit, remaining 392 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      27.55 ms /   356 runs   (    0.08 ms per token, 12921.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10837.60 ms /   392 tokens (   27.65 ms per token,    36.17 tokens per second)\n",
      "llama_print_timings:        eval time =   24033.36 ms /   355 runs   (   67.70 ms per token,    14.77 tokens per second)\n",
      "llama_print_timings:       total time =   35255.96 ms /   747 tokens\n",
      "Generating embeddings: 100%|██████████| 24/24 [00:00<00:00, 400.39it/s]\n",
      "Processing nodes:  32%|███▏      | 21/66 [13:35<28:46, 38.36s/it]Llama.generate: 121 prefix-match hit, remaining 451 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      40.01 ms /   512 runs   (    0.08 ms per token, 12798.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11286.56 ms /   451 tokens (   25.03 ms per token,    39.96 tokens per second)\n",
      "llama_print_timings:        eval time =   33076.46 ms /   511 runs   (   64.73 ms per token,    15.45 tokens per second)\n",
      "llama_print_timings:       total time =   44995.98 ms /   962 tokens\n",
      "Generating embeddings: 100%|██████████| 20/20 [00:00<00:00, 439.73it/s]\n",
      "Processing nodes:  33%|███▎      | 22/66 [14:20<29:36, 40.37s/it]Llama.generate: 121 prefix-match hit, remaining 484 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      41.21 ms /   512 runs   (    0.08 ms per token, 12424.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11467.16 ms /   484 tokens (   23.69 ms per token,    42.21 tokens per second)\n",
      "llama_print_timings:        eval time =   33175.04 ms /   511 runs   (   64.92 ms per token,    15.40 tokens per second)\n",
      "llama_print_timings:       total time =   45324.56 ms /   995 tokens\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00, 83.68it/s]\n",
      "Processing nodes:  35%|███▍      | 23/66 [15:05<30:00, 41.87s/it]Llama.generate: 121 prefix-match hit, remaining 476 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      36.90 ms /   439 runs   (    0.08 ms per token, 11898.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11597.06 ms /   476 tokens (   24.36 ms per token,    41.04 tokens per second)\n",
      "llama_print_timings:        eval time =   27794.45 ms /   438 runs   (   63.46 ms per token,    15.76 tokens per second)\n",
      "llama_print_timings:       total time =   39960.74 ms /   914 tokens\n",
      "Generating embeddings: 100%|██████████| 20/20 [00:00<00:00, 393.57it/s]\n",
      "Processing nodes:  36%|███▋      | 24/66 [15:45<28:55, 41.32s/it]Llama.generate: 121 prefix-match hit, remaining 471 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      33.20 ms /   427 runs   (    0.08 ms per token, 12862.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11231.84 ms /   471 tokens (   23.85 ms per token,    41.93 tokens per second)\n",
      "llama_print_timings:        eval time =   27136.85 ms /   426 runs   (   63.70 ms per token,    15.70 tokens per second)\n",
      "llama_print_timings:       total time =   38836.85 ms /   897 tokens\n",
      "Generating embeddings: 100%|██████████| 23/23 [00:00<00:00, 374.36it/s]\n",
      "Processing nodes:  38%|███▊      | 25/66 [16:24<27:44, 40.59s/it]Llama.generate: 121 prefix-match hit, remaining 397 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      37.17 ms /   397 runs   (    0.09 ms per token, 10680.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10843.18 ms /   397 tokens (   27.31 ms per token,    36.61 tokens per second)\n",
      "llama_print_timings:        eval time =   23135.02 ms /   396 runs   (   58.42 ms per token,    17.12 tokens per second)\n",
      "llama_print_timings:       total time =   34488.04 ms /   793 tokens\n",
      "Generating embeddings: 100%|██████████| 23/23 [00:00<00:00, 367.18it/s]\n",
      "Processing nodes:  39%|███▉      | 26/66 [16:59<25:51, 38.78s/it]Llama.generate: 121 prefix-match hit, remaining 447 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      25.50 ms /   265 runs   (    0.10 ms per token, 10394.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11206.41 ms /   447 tokens (   25.07 ms per token,    39.89 tokens per second)\n",
      "llama_print_timings:        eval time =   16026.22 ms /   264 runs   (   60.71 ms per token,    16.47 tokens per second)\n",
      "llama_print_timings:       total time =   27535.34 ms /   711 tokens\n",
      "Generating embeddings: 100%|██████████| 12/12 [00:00<00:00, 331.85it/s]\n",
      "Processing nodes:  41%|████      | 27/66 [17:26<23:01, 35.43s/it]Llama.generate: 121 prefix-match hit, remaining 465 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      42.88 ms /   512 runs   (    0.08 ms per token, 11940.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11365.30 ms /   465 tokens (   24.44 ms per token,    40.91 tokens per second)\n",
      "llama_print_timings:        eval time =   31979.84 ms /   511 runs   (   62.58 ms per token,    15.98 tokens per second)\n",
      "llama_print_timings:       total time =   44072.36 ms /   976 tokens\n",
      "Generating embeddings: 100%|██████████| 34/34 [00:00<00:00, 398.43it/s]\n",
      "Processing nodes:  42%|████▏     | 28/66 [18:11<24:05, 38.05s/it]Llama.generate: 121 prefix-match hit, remaining 475 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      25.48 ms /   318 runs   (    0.08 ms per token, 12482.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11484.81 ms /   475 tokens (   24.18 ms per token,    41.36 tokens per second)\n",
      "llama_print_timings:        eval time =   20771.66 ms /   317 runs   (   65.53 ms per token,    15.26 tokens per second)\n",
      "llama_print_timings:       total time =   32666.10 ms /   792 tokens\n",
      "Generating embeddings: 100%|██████████| 22/22 [00:00<00:00, 360.69it/s]\n",
      "Processing nodes:  44%|████▍     | 29/66 [18:43<22:28, 36.46s/it]Llama.generate: 121 prefix-match hit, remaining 477 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      42.80 ms /   512 runs   (    0.08 ms per token, 11963.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11456.82 ms /   477 tokens (   24.02 ms per token,    41.63 tokens per second)\n",
      "llama_print_timings:        eval time =   35398.42 ms /   511 runs   (   69.27 ms per token,    14.44 tokens per second)\n",
      "llama_print_timings:       total time =   47582.73 ms /   988 tokens\n",
      "Generating embeddings: 100%|██████████| 12/12 [00:00<00:00, 377.38it/s]\n",
      "Processing nodes:  45%|████▌     | 30/66 [19:31<23:53, 39.81s/it]Llama.generate: 121 prefix-match hit, remaining 418 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      40.84 ms /   512 runs   (    0.08 ms per token, 12535.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11028.01 ms /   418 tokens (   26.38 ms per token,    37.90 tokens per second)\n",
      "llama_print_timings:        eval time =   34857.19 ms /   511 runs   (   68.21 ms per token,    14.66 tokens per second)\n",
      "llama_print_timings:       total time =   46567.40 ms /   929 tokens\n",
      "Generating embeddings: 100%|██████████| 12/12 [00:00<00:00, 382.63it/s]\n",
      "Processing nodes:  47%|████▋     | 31/66 [20:18<24:24, 41.85s/it]Llama.generate: 113 prefix-match hit, remaining 443 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      33.88 ms /   379 runs   (    0.09 ms per token, 11185.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12529.89 ms /   443 tokens (   28.28 ms per token,    35.36 tokens per second)\n",
      "llama_print_timings:        eval time =   21767.49 ms /   378 runs   (   57.59 ms per token,    17.37 tokens per second)\n",
      "llama_print_timings:       total time =   34821.59 ms /   821 tokens\n",
      "Generating embeddings: 100%|██████████| 21/21 [00:00<00:00, 283.31it/s]\n",
      "Processing nodes:  48%|████▊     | 32/66 [20:53<22:32, 39.77s/it]Llama.generate: 118 prefix-match hit, remaining 480 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      38.47 ms /   389 runs   (    0.10 ms per token, 10110.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12160.86 ms /   480 tokens (   25.34 ms per token,    39.47 tokens per second)\n",
      "llama_print_timings:        eval time =   20663.05 ms /   388 runs   (   53.26 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:       total time =   33375.63 ms /   868 tokens\n",
      "Generating embeddings: 100%|██████████| 20/20 [00:00<00:00, 357.93it/s]\n",
      "Processing nodes:  50%|█████     | 33/66 [21:26<20:49, 37.87s/it]Llama.generate: 118 prefix-match hit, remaining 483 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      42.90 ms /   512 runs   (    0.08 ms per token, 11935.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12445.75 ms /   483 tokens (   25.77 ms per token,    38.81 tokens per second)\n",
      "llama_print_timings:        eval time =   27725.94 ms /   511 runs   (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:       total time =   40897.38 ms /   994 tokens\n",
      "Generating embeddings: 100%|██████████| 34/34 [00:00<00:00, 450.75it/s]\n",
      "Processing nodes:  52%|█████▏    | 34/66 [22:07<20:41, 38.81s/it]Llama.generate: 119 prefix-match hit, remaining 473 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      41.71 ms /   512 runs   (    0.08 ms per token, 12275.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12662.16 ms /   473 tokens (   26.77 ms per token,    37.36 tokens per second)\n",
      "llama_print_timings:        eval time =   27047.72 ms /   511 runs   (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:       total time =   40397.90 ms /   984 tokens\n",
      "Generating embeddings: 100%|██████████| 13/13 [00:00<00:00, 409.85it/s]\n",
      "Processing nodes:  53%|█████▎    | 35/66 [22:47<20:18, 39.30s/it]Llama.generate: 118 prefix-match hit, remaining 480 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      30.12 ms /   398 runs   (    0.08 ms per token, 13214.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11366.62 ms /   480 tokens (   23.68 ms per token,    42.23 tokens per second)\n",
      "llama_print_timings:        eval time =   23430.98 ms /   397 runs   (   59.02 ms per token,    16.94 tokens per second)\n",
      "llama_print_timings:       total time =   35229.82 ms /   877 tokens\n",
      "Generating embeddings: 100%|██████████| 25/25 [00:00<00:00, 406.82it/s]\n",
      "Processing nodes:  55%|█████▍    | 36/66 [23:23<19:02, 38.10s/it]Llama.generate: 119 prefix-match hit, remaining 460 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      28.63 ms /   318 runs   (    0.09 ms per token, 11107.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11493.57 ms /   460 tokens (   24.99 ms per token,    40.02 tokens per second)\n",
      "llama_print_timings:        eval time =   17033.31 ms /   317 runs   (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:       total time =   28914.05 ms /   777 tokens\n",
      "Generating embeddings: 100%|██████████| 23/23 [00:00<00:00, 398.55it/s]\n",
      "Processing nodes:  56%|█████▌    | 37/66 [23:52<17:05, 35.36s/it]Llama.generate: 118 prefix-match hit, remaining 472 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      37.63 ms /   379 runs   (    0.10 ms per token, 10071.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12301.12 ms /   472 tokens (   26.06 ms per token,    38.37 tokens per second)\n",
      "llama_print_timings:        eval time =   20254.40 ms /   378 runs   (   53.58 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:       total time =   33116.30 ms /   850 tokens\n",
      "Generating embeddings: 100%|██████████| 23/23 [00:00<00:00, 328.54it/s]\n",
      "Processing nodes:  58%|█████▊    | 38/66 [24:25<16:12, 34.71s/it]Llama.generate: 118 prefix-match hit, remaining 475 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      54.79 ms /   512 runs   (    0.11 ms per token,  9344.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12073.75 ms /   475 tokens (   25.42 ms per token,    39.34 tokens per second)\n",
      "llama_print_timings:        eval time =   26505.51 ms /   511 runs   (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:       total time =   39411.27 ms /   986 tokens\n",
      "Generating embeddings: 100%|██████████| 20/20 [00:00<00:00, 388.44it/s]\n",
      "Processing nodes:  59%|█████▉    | 39/66 [25:04<16:15, 36.14s/it]Llama.generate: 118 prefix-match hit, remaining 418 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      33.01 ms /   342 runs   (    0.10 ms per token, 10359.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11629.85 ms /   418 tokens (   27.82 ms per token,    35.94 tokens per second)\n",
      "llama_print_timings:        eval time =   18278.58 ms /   341 runs   (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:       total time =   30393.76 ms /   759 tokens\n",
      "Generating embeddings: 100%|██████████| 22/22 [00:00<00:00, 322.87it/s]\n",
      "Processing nodes:  61%|██████    | 40/66 [25:35<14:55, 34.45s/it]Llama.generate: 118 prefix-match hit, remaining 463 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      27.10 ms /   284 runs   (    0.10 ms per token, 10480.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11865.93 ms /   463 tokens (   25.63 ms per token,    39.02 tokens per second)\n",
      "llama_print_timings:        eval time =   17451.34 ms /   283 runs   (   61.67 ms per token,    16.22 tokens per second)\n",
      "llama_print_timings:       total time =   29695.81 ms /   746 tokens\n",
      "Generating embeddings: 100%|██████████| 20/20 [00:00<00:00, 481.37it/s]\n",
      "Processing nodes:  62%|██████▏   | 41/66 [26:05<13:45, 33.04s/it]Llama.generate: 118 prefix-match hit, remaining 487 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      31.29 ms /   348 runs   (    0.09 ms per token, 11122.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11978.51 ms /   487 tokens (   24.60 ms per token,    40.66 tokens per second)\n",
      "llama_print_timings:        eval time =   19683.87 ms /   347 runs   (   56.73 ms per token,    17.63 tokens per second)\n",
      "llama_print_timings:       total time =   32140.86 ms /   834 tokens\n",
      "Generating embeddings: 100%|██████████| 18/18 [00:00<00:00, 450.33it/s]\n",
      "Processing nodes:  64%|██████▎   | 42/66 [26:37<13:06, 32.78s/it]Llama.generate: 118 prefix-match hit, remaining 233 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      46.80 ms /   512 runs   (    0.09 ms per token, 10939.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10164.38 ms /   233 tokens (   43.62 ms per token,    22.92 tokens per second)\n",
      "llama_print_timings:        eval time =   28209.01 ms /   511 runs   (   55.20 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:       total time =   39160.81 ms /   744 tokens\n",
      "Generating embeddings: 100%|██████████| 35/35 [00:00<00:00, 455.98it/s]\n",
      "Processing nodes:  65%|██████▌   | 43/66 [27:16<13:18, 34.72s/it]Llama.generate: 113 prefix-match hit, remaining 479 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      48.38 ms /   512 runs   (    0.09 ms per token, 10583.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12145.59 ms /   479 tokens (   25.36 ms per token,    39.44 tokens per second)\n",
      "llama_print_timings:        eval time =   28711.45 ms /   511 runs   (   56.19 ms per token,    17.80 tokens per second)\n",
      "llama_print_timings:       total time =   41684.78 ms /   990 tokens\n",
      "Generating embeddings: 100%|██████████| 17/17 [00:00<00:00, 393.38it/s]\n",
      "Processing nodes:  67%|██████▋   | 44/66 [27:58<13:30, 36.83s/it]Llama.generate: 125 prefix-match hit, remaining 445 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      47.69 ms /   512 runs   (    0.09 ms per token, 10735.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13135.54 ms /   445 tokens (   29.52 ms per token,    33.88 tokens per second)\n",
      "llama_print_timings:        eval time =   41233.36 ms /   511 runs   (   80.69 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =   55178.58 ms /   956 tokens\n",
      "Generating embeddings: 100%|██████████| 16/16 [00:00<00:00, 385.10it/s]\n",
      "Processing nodes:  68%|██████▊   | 45/66 [28:53<14:49, 42.35s/it]Llama.generate: 113 prefix-match hit, remaining 466 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      48.02 ms /   512 runs   (    0.09 ms per token, 10663.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14142.45 ms /   466 tokens (   30.35 ms per token,    32.95 tokens per second)\n",
      "llama_print_timings:        eval time =   33524.60 ms /   511 runs   (   65.61 ms per token,    15.24 tokens per second)\n",
      "llama_print_timings:       total time =   48460.16 ms /   977 tokens\n",
      "Generating embeddings: 100%|██████████| 21/21 [00:00<00:00, 350.46it/s]\n",
      "Processing nodes:  70%|██████▉   | 46/66 [29:42<14:44, 44.20s/it]Llama.generate: 117 prefix-match hit, remaining 486 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      31.18 ms /   348 runs   (    0.09 ms per token, 11162.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12826.84 ms /   486 tokens (   26.39 ms per token,    37.89 tokens per second)\n",
      "llama_print_timings:        eval time =   18868.15 ms /   347 runs   (   54.38 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:       total time =   32173.39 ms /   833 tokens\n",
      "Generating embeddings: 100%|██████████| 19/19 [00:00<00:00, 418.56it/s]\n",
      "Processing nodes:  71%|███████   | 47/66 [30:14<12:51, 40.61s/it]Llama.generate: 117 prefix-match hit, remaining 478 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      48.27 ms /   512 runs   (    0.09 ms per token, 10606.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12956.78 ms /   478 tokens (   27.11 ms per token,    36.89 tokens per second)\n",
      "llama_print_timings:        eval time =   29193.04 ms /   511 runs   (   57.13 ms per token,    17.50 tokens per second)\n",
      "llama_print_timings:       total time =   42940.31 ms /   989 tokens\n",
      "Generating embeddings: 100%|██████████| 26/26 [00:00<00:00, 435.75it/s]\n",
      "Processing nodes:  73%|███████▎  | 48/66 [30:57<12:23, 41.33s/it]Llama.generate: 118 prefix-match hit, remaining 479 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      50.16 ms /   512 runs   (    0.10 ms per token, 10208.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12004.79 ms /   479 tokens (   25.06 ms per token,    39.90 tokens per second)\n",
      "llama_print_timings:        eval time =   31331.32 ms /   511 runs   (   61.31 ms per token,    16.31 tokens per second)\n",
      "llama_print_timings:       total time =   44126.38 ms /   990 tokens\n",
      "Generating embeddings: 100%|██████████| 15/15 [00:00<00:00, 429.08it/s]\n",
      "Processing nodes:  74%|███████▍  | 49/66 [31:41<11:57, 42.19s/it]Llama.generate: 117 prefix-match hit, remaining 392 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      49.51 ms /   512 runs   (    0.10 ms per token, 10342.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11210.69 ms /   392 tokens (   28.60 ms per token,    34.97 tokens per second)\n",
      "llama_print_timings:        eval time =   29554.72 ms /   511 runs   (   57.84 ms per token,    17.29 tokens per second)\n",
      "llama_print_timings:       total time =   41531.42 ms /   903 tokens\n",
      "Generating embeddings: 100%|██████████| 15/15 [00:00<00:00, 365.31it/s]\n",
      "Processing nodes:  76%|███████▌  | 50/66 [32:23<11:12, 42.00s/it]Llama.generate: 113 prefix-match hit, remaining 490 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      49.34 ms /   512 runs   (    0.10 ms per token, 10376.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12141.68 ms /   490 tokens (   24.78 ms per token,    40.36 tokens per second)\n",
      "llama_print_timings:        eval time =   26323.60 ms /   511 runs   (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:       total time =   39233.97 ms /  1001 tokens\n",
      "Generating embeddings: 100%|██████████| 27/27 [00:00<00:00, 377.99it/s]\n",
      "Processing nodes:  77%|███████▋  | 51/66 [33:02<10:17, 41.20s/it]Llama.generate: 124 prefix-match hit, remaining 468 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      31.67 ms /   328 runs   (    0.10 ms per token, 10355.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11867.49 ms /   468 tokens (   25.36 ms per token,    39.44 tokens per second)\n",
      "llama_print_timings:        eval time =   19274.24 ms /   327 runs   (   58.94 ms per token,    16.97 tokens per second)\n",
      "llama_print_timings:       total time =   31601.31 ms /   795 tokens\n",
      "Generating embeddings: 100%|██████████| 19/19 [00:00<00:00, 458.80it/s]\n",
      "Processing nodes:  79%|███████▉  | 52/66 [33:34<08:56, 38.33s/it]Llama.generate: 124 prefix-match hit, remaining 470 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      35.17 ms /   337 runs   (    0.10 ms per token,  9582.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11754.61 ms /   470 tokens (   25.01 ms per token,    39.98 tokens per second)\n",
      "llama_print_timings:        eval time =   17388.55 ms /   336 runs   (   51.75 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:       total time =   29663.06 ms /   806 tokens\n",
      "Generating embeddings: 100%|██████████| 24/24 [00:00<00:00, 337.78it/s]\n",
      "Processing nodes:  80%|████████  | 53/66 [34:03<07:44, 35.76s/it]Llama.generate: 124 prefix-match hit, remaining 470 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      50.37 ms /   512 runs   (    0.10 ms per token, 10165.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11732.10 ms /   470 tokens (   24.96 ms per token,    40.06 tokens per second)\n",
      "llama_print_timings:        eval time =   25626.22 ms /   511 runs   (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_print_timings:       total time =   38159.60 ms /   981 tokens\n",
      "Generating embeddings: 100%|██████████| 19/19 [00:00<00:00, 474.94it/s]\n",
      "Processing nodes:  82%|████████▏ | 54/66 [34:41<07:17, 36.50s/it]Llama.generate: 124 prefix-match hit, remaining 455 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      25.11 ms /   275 runs   (    0.09 ms per token, 10951.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11914.88 ms /   455 tokens (   26.19 ms per token,    38.19 tokens per second)\n",
      "llama_print_timings:        eval time =   13657.99 ms /   274 runs   (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_print_timings:       total time =   25936.47 ms /   729 tokens\n",
      "Generating embeddings: 100%|██████████| 17/17 [00:00<00:00, 414.23it/s]\n",
      "Processing nodes:  83%|████████▎ | 55/66 [35:07<06:06, 33.34s/it]Llama.generate: 124 prefix-match hit, remaining 461 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      23.60 ms /   258 runs   (    0.09 ms per token, 10932.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12147.02 ms /   461 tokens (   26.35 ms per token,    37.95 tokens per second)\n",
      "llama_print_timings:        eval time =   13640.83 ms /   257 runs   (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:       total time =   26081.23 ms /   718 tokens\n",
      "Generating embeddings: 100%|██████████| 19/19 [00:00<00:00, 483.85it/s]\n",
      "Processing nodes:  85%|████████▍ | 56/66 [35:34<05:11, 31.18s/it]Llama.generate: 124 prefix-match hit, remaining 474 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      31.59 ms /   347 runs   (    0.09 ms per token, 10985.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11797.41 ms /   474 tokens (   24.89 ms per token,    40.18 tokens per second)\n",
      "llama_print_timings:        eval time =   17922.77 ms /   346 runs   (   51.80 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:       total time =   30219.74 ms /   820 tokens\n",
      "Generating embeddings: 100%|██████████| 20/20 [00:00<00:00, 472.83it/s]\n",
      "Processing nodes:  86%|████████▋ | 57/66 [36:04<04:38, 30.91s/it]Llama.generate: 124 prefix-match hit, remaining 460 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      32.45 ms /   349 runs   (    0.09 ms per token, 10755.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12083.58 ms /   460 tokens (   26.27 ms per token,    38.07 tokens per second)\n",
      "llama_print_timings:        eval time =   20257.34 ms /   348 runs   (   58.21 ms per token,    17.18 tokens per second)\n",
      "llama_print_timings:       total time =   32823.40 ms /   808 tokens\n",
      "Generating embeddings: 100%|██████████| 21/21 [00:00<00:00, 342.69it/s]\n",
      "Processing nodes:  88%|████████▊ | 58/66 [36:37<04:12, 31.50s/it]Llama.generate: 124 prefix-match hit, remaining 482 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      30.65 ms /   362 runs   (    0.08 ms per token, 11810.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12117.01 ms /   482 tokens (   25.14 ms per token,    39.78 tokens per second)\n",
      "llama_print_timings:        eval time =   19798.64 ms /   361 runs   (   54.84 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:       total time =   32402.61 ms /   843 tokens\n",
      "Generating embeddings: 100%|██████████| 27/27 [00:00<00:00, 418.46it/s]\n",
      "Processing nodes:  89%|████████▉ | 59/66 [37:09<03:42, 31.80s/it]Llama.generate: 124 prefix-match hit, remaining 475 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      29.49 ms /   332 runs   (    0.09 ms per token, 11258.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12470.40 ms /   475 tokens (   26.25 ms per token,    38.09 tokens per second)\n",
      "llama_print_timings:        eval time =   18581.71 ms /   331 runs   (   56.14 ms per token,    17.81 tokens per second)\n",
      "llama_print_timings:       total time =   31499.83 ms /   806 tokens\n",
      "Generating embeddings: 100%|██████████| 23/23 [00:00<00:00, 321.60it/s]\n",
      "Processing nodes:  91%|█████████ | 60/66 [37:41<03:10, 31.73s/it]Llama.generate: 124 prefix-match hit, remaining 459 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      43.55 ms /   394 runs   (    0.11 ms per token,  9047.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12177.79 ms /   459 tokens (   26.53 ms per token,    37.69 tokens per second)\n",
      "llama_print_timings:        eval time =   21922.71 ms /   393 runs   (   55.78 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:       total time =   34722.03 ms /   852 tokens\n",
      "Generating embeddings: 100%|██████████| 22/22 [00:00<00:00, 325.75it/s]\n",
      "Processing nodes:  92%|█████████▏| 61/66 [38:16<02:43, 32.66s/it]Llama.generate: 124 prefix-match hit, remaining 465 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      43.69 ms /   455 runs   (    0.10 ms per token, 10414.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11860.54 ms /   465 tokens (   25.51 ms per token,    39.21 tokens per second)\n",
      "llama_print_timings:        eval time =   22083.00 ms /   454 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_print_timings:       total time =   34660.57 ms /   919 tokens\n",
      "Generating embeddings: 100%|██████████| 21/21 [00:00<00:00, 318.15it/s]\n",
      "Processing nodes:  94%|█████████▍| 62/66 [38:50<02:13, 33.28s/it]Llama.generate: 124 prefix-match hit, remaining 258 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      26.55 ms /   295 runs   (    0.09 ms per token, 11111.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10426.02 ms /   258 tokens (   40.41 ms per token,    24.75 tokens per second)\n",
      "llama_print_timings:        eval time =   15200.70 ms /   294 runs   (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:       total time =   26016.31 ms /   552 tokens\n",
      "Generating embeddings: 100%|██████████| 20/20 [00:00<00:00, 502.28it/s]\n",
      "Processing nodes:  95%|█████████▌| 63/66 [39:16<01:33, 31.12s/it]Llama.generate: 113 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      43.84 ms /   512 runs   (    0.09 ms per token, 11680.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8209.54 ms /    13 tokens (  631.50 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:        eval time =   27053.64 ms /   511 runs   (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:       total time =   35996.47 ms /   524 tokens\n",
      "Generating embeddings: 100%|██████████| 7/7 [00:00<00:00, 253.26it/s]\n",
      "Processing nodes:  97%|█████████▋| 64/66 [39:52<01:05, 32.59s/it]Llama.generate: 113 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      45.14 ms /   512 runs   (    0.09 ms per token, 11343.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8369.42 ms /    13 tokens (  643.80 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:        eval time =   27140.17 ms /   511 runs   (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:       total time =   36214.56 ms /   524 tokens\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00, 75.35it/s]\n",
      "Processing nodes:  98%|█████████▊| 65/66 [40:29<00:33, 33.69s/it]Llama.generate: 113 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =      21.18 ms /   248 runs   (    0.09 ms per token, 11711.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8790.82 ms /    32 tokens (  274.71 ms per token,     3.64 tokens per second)\n",
      "llama_print_timings:        eval time =   13591.96 ms /   247 runs   (   55.03 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:       total time =   22688.84 ms /   279 tokens\n",
      "Generating embeddings: 100%|██████████| 9/9 [00:00<00:00, 379.63it/s]\n",
      "Processing nodes: 100%|██████████| 66/66 [40:51<00:00, 37.15s/it]\n"
     ]
    }
   ],
   "source": [
    "graph_store = SimpleGraphStore()\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "\n",
    "index = KnowledgeGraphIndex.from_documents(\n",
    "    wikitext_docs[:10],\n",
    "    storage_context=storage_context,\n",
    "    max_triplets_per_chunk=10,\n",
    "    include_embeddings=True,\n",
    "    llm=llm_llama3,\n",
    "    embed_model=embed_model,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    include_text=True,\n",
    "    response_mode=\"tree_summarize\",\n",
    "    embedding_mode=\"hybrid\",\n",
    "    similarity_top_k=5,\n",
    ")\n",
    "\n",
    "def rag_with_knowledge_graph(query: str):\n",
    "    retrieval_results = query_engine.retrieve(query)\n",
    "    \n",
    "    context = \"\\n\".join([node.get_content() for node in retrieval_results])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Based on the following information from a knowledge graph:\n",
    "    {context}\n",
    "    \n",
    "    Please answer the following question:\n",
    "    {query}\n",
    "    \n",
    "    If the information is not sufficient to answer the question, please say so.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm_llama3.complete(prompt)\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "def multi_hop_rag(query: str, max_hops: int = 3):\n",
    "    context = \"\"\n",
    "    for hop in range(max_hops):\n",
    "        retrieval_results = query_engine.retrieve(query)\n",
    "        hop_context = \"\\n\".join([node.get_content() for node in retrieval_results])\n",
    "        context += f\"\\nHop {hop + 1}:\\n{hop_context}\\n\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Based on the following information from a knowledge graph:\n",
    "        {context}\n",
    "        \n",
    "        Please answer the following question:\n",
    "        {query}\n",
    "        \n",
    "        If you can answer the question, do so. If not, what additional information do you need?\n",
    "        \"\"\"\n",
    "        \n",
    "        response = llm_llama3.complete(prompt)\n",
    "        \n",
    "        if \"additional information\" not in response.text.lower():\n",
    "            break\n",
    "        \n",
    "        query = response.text  # Use the response as the next query\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 67 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =    9485.70 ms\n",
      "llama_print_timings:      sample time =       4.40 ms /    43 runs   (    0.10 ms per token,  9768.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    2507.34 ms /    43 runs   (   58.31 ms per token,    17.15 tokens per second)\n",
      "llama_print_timings:       total time =    2556.11 ms /    43 tokens\n",
      "\n",
      "llama_print_timings:        load time =   12741.16 ms\n",
      "llama_print_timings:      sample time =      14.99 ms /   157 runs   (    0.10 ms per token, 10471.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  140800.59 ms /  4662 tokens (   30.20 ms per token,    33.11 tokens per second)\n",
      "llama_print_timings:        eval time =   10266.89 ms /   156 runs   (   65.81 ms per token,    15.19 tokens per second)\n",
      "llama_print_timings:       total time =  151297.88 ms /  4818 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Valkyria Chronicles?\n",
      "Answer: \n",
      "\n",
      "\n",
      "\n",
      "The information provided does not directly answer the question \"What is Valkyria Chronicles?\" as it only describes Valkyria Chronicles III, which is the third game in the Valkyria Chronicles series. However, based on the context, it can be inferred that Valkyria Chronicles is a tactical role-playing game series. Therefore, I will provide an answer based on this inference:\n",
      "\n",
      "Valkyria Chronicles is a tactical role-playing game series.\n",
      "\n",
      "Please note that this answer is based on the provided information and may not be the exact definition of Valkyria Chronicles. A more accurate answer would require additional information about the series. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "If you want to know more about Valkyria Chronicles, you can refer to the provided information or search for more information about the series.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is Valkyria Chronicles?\"\n",
    "answer = rag_with_knowledge_graph(question)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
